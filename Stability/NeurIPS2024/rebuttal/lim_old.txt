While we explicitly describe the topology and dimensionality of the identified invariant manifolds for a representative set, our results indicate that most solutions exhibit a ring invariant manifold with a slow flow. This separation of timescales necessarily exists for well-trained networks; however, the analysis is not guaranteed to work for systems without a fast-slow decomposition.

To identify solutions with a fast-slow decomposition, we rely solely on the generalization property of the network, measured in terms of the normalized mean square error over ten times longer trials. The possible solutions the networks can find are restricted by having a linear output mapping. For a nonlinear output mapping, a possible solution for analog memory is the quasi-periodic toroidal attractor, but this is not a possible solution with a linear output mapping. While our analysis methods can identify these limit sets, we do not have a straightforward way to parametrize the invariant manifold.

