\documentclass{article}
\usepackage{arxiv}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amssymb, amsmath, amsthm, amsfonts}
\usepackage{thmtools, mathtools, mathrsfs, dsfont}
\usepackage{bbm}
\usepackage[square,numbers]{natbib}
\bibliographystyle{abbrvnat}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage[pdftex]{graphicx}  %remove demo option in your document
\usepackage{sidecap}

\graphicspath{{figures}}

\newtheorem{theorem}{Theorem}
\newtheorem{proposition}{Proposition}
\theoremstyle{definition}
\newtheorem{definition}{Definition}
\theoremstyle{remark}
\newtheorem{remark}{Remark}

\newcommand{\reals}{\mathbb{R}}
\newcommand{\sep}{\operatorname{sep}}
\newcommand{\cl}{\operatorname{cl}}
\newcommand{\vol}{\operatorname{vol}}
\newcommand{\boa}{\operatorname{BoA}}

\title{Approximation of multi-stable dynamical systems on infinite horizons}
\author{\'Abel S\'agodi and Il Memming Park}
\date{\today}

\begin{document}

\maketitle

\section{Introduction}
Recurrent Neural Networks (RNNs) are believed to be universal approximators.
However, universal approximation results with RNNs are limited in scope.
Existing results about approximating dynamical systems either focus on finite time horizon approximation or on approximating stable dynamical systems on an infinite horizon.
This misses important behavior of the system (e.g. temporal generalization of the approximation).


A key motivation for extending approximation results to the infinite horizon lies in its ability to capture qualitative behaviors over time. For example, infinite horizon approximation allows us to better understand how a system's behavior unfolds over extended periods, providing insights into stability, transitions, and equilibrium states.
 Furthermore, an effective infinite horizon approximation ensures robustness: small perturbations, such as noise, do not result in abrupt increases in approximation error, but instead produce gradual, smooth deviations in the system's trajectory.
%the second point needs to be worked out: with added noise the error would jump for trajectories at separatrices

%We seek to extend approximation results for dynamical systems to multi-stable systems (systems without chaos) on an infinite horizon through Neural ODEs (NODEs).
Our work aims to bridge this gap by extending the approximation of dynamical systems to multi-stable systems—those with multiple equilibrium states but no chaotic behavior—over an infinite horizon. 
To achieve this, we leverage Neural Ordinary Differential Equations (NODEs) as a framework for constructing such approximations.
% By using NODEs, we can model continuous-time dynamical systems while ensuring that key properties, such as stability and smooth error bounds under perturbations, are maintained.
This framework allows us to rigorously study the approximation of multi-stable systems in settings where classical RNNs may struggle, laying the groundwork for future advances in both theory and applications of neural approximators in long-term dynamical modeling.

%mention that vanilla RNNs are not universal approximators?





\section{Approximation of dynamical systems}
%sota 

Accurately approximating dynamical systems is essential for understanding and predicting complex behaviors across a range of applications, from robotics to climate modeling.
Recent advances in machine learning have enabled data-driven approaches to approximating these systems, providing new ways to model complex dynamics over extended periods.
Here, we review key approaches in the literature and highlight emerging techniques that address these challenges, before we introduce our method that extends to multi-stable and complex systems over infinite horizons.

For an overview of the literature, see [litrev]
See also \citep{li2022approximation} and \citep{jiang2023brief}.




%vector fields (which is just FNN setting)
\subsection{Approximating vector fields}
Neural networks, particularly FNNs, can approximate smooth functions effectively, making them suitable for approximating vector fields.

\subsubsection{Spiking neural network}
%only approximates vector field 
In limit $N\rightarrow\infty$ spiking network (ODE with jumps) approximates a vector field (for a continuous ODE) \citep{podlaski2024approximating}. 

%so of type diffeomorphism?


\subsection{Diffeomorphisms}
%diff/flow
Invertible neural networks have a universal approximation property for a  large class of diffeomorphisms   \citep{ishikawa2023universal}.




\subsection{Approximation of dynamics on compact time intervals}
%An RNN with a sufficient number of hidden units and appropriate non-linear activation functions (such as tanh or sigmoid) can approximate any dynamic system or time-dependent function to arbitrary precision, provided the system operates on compact time intervals.

The universal approximation theorem for RNNs, which extends the classical result for feedforward neural networks, guarantees that RNNs can approximate the mapping from a sequence of inputs to outputs for any continuous-time process, including those governed by differential equations.

% \citep{funahashi1993approximation}
This property has been formally proven for systems operating over finite time intervals. Specifically, \citet{funahashi1993approximation} showed that RNNs can approximate the time-dependent behaviors of dynamical systems, making them suitable for tasks like time-series prediction, control systems, and the modeling of sequential data.

Since the results concern a compact time interval, to approximate dynamics it is enough to approximate $f$, i.e., these approaches convert RNN approximation to FNN approximation.
This is in general not true for the unbounded case, as the approximation error can be magnified by the dynamics.
%merge
Existing results have established that recurrent nets are capable of generating simulated trajectories that approximate true system trajectories within arbitrary error tolerance over a finite time interval.
Most of these results rely on Gr\:onwall’s inequality to control the difference between the trajectories of the original system and its approximation, which incurs an exponential degradation of approximation accuracy over time
\citep{sontag1992neural, sontag1998learning, funahashi1993approximation,chow2000modeling, li2005approximation}.

\paragraph{Discrete sequence-to-sequence mapping}
Uniform approximation of a state space trajectory (with time-varying inputs) produced by either a discrete-time nonlinear system or a continuous function on a closed discrete-time interval \citep{jin1995universal}.

The first $p$ output neural units of a dynamic $n$-dimensional neural model approximate at a desired proximity a $p$-dimensional dynamic system with $n > p$ \citep{kambhampati2000approximation}.

Any function can be approximated arbitrarily well in probability with a recurrent neural network\citep{hammer2000approximation}. 
% where ... can be computed by one neuron whose activation function $\sigma$ possesses a local linearity.\citep{hammer2000approximation}


RNNs with continuous sigmoidal activation function have the UAP for finite number of time steps \citep{schafer2007}.

Discrete-time RNNs are universal approximators of discrete-time systems \citep{aguiar2023universal}.

%\paragraph{Neural oscillators}
\paragraph{Continuous time}
Neural oscillators have the universal approximation property on compact time intervals \citep{lanthaler2023neuraloscillators}.



%FPS%fading
\subsection{Approximation of fading memory systems}
Fading memory \citep{boyd1985fading}


\begin{definition}[Fading memory Property (FMP)]
Let $x_1, x_2$ be bounded sequences indexed by $\mathbb{R}$, and let $H$ be a sequence of causal, shift-equivariant (also called time-homogeneous) functionals.
Here, causal means $H_t(x) = H_t(x(-\infty,t])$ for all $t$.
We say that $H$ has the \textbf{FMP} if there is a monotonically decreasing function $w : \mathbb{R}^+ \to (0, 1]$ such that for any $\varepsilon > 0$ there exists $\delta > 0$ with 
\[
|H_t(x_1) - H_t(x_2)| < \varepsilon \quad \text{whenever} \quad \sup_{s \in (-\infty, t]} |x_1(s) - x_2(s)| w(t - s) < \delta.
\]
\end{definition}

 Typically, the FMP is used to reduce the approximation problem to one over a finite, bounded index set, and then appeal to the density of fully connected neural network to obtain approximation \citep{gonon2021fading}. %more examples


\begin{remark}
Every fading-memory system could be uniformly approximated arbitrarily closely over the set of systems with 'linear dynamics'\citep{matthews1993approximating}. %Theorem 3+4
Using the perceptron to uniformly approximate the external representation of a fading-memory system results in a finite-memory system model, called the perceptron filter \citep{matthews1993approximating}.
\end{remark}


\paragraph{Linear RNNs}
\citet{li2020curse} investigate Linear RNNs in continuous time. % and therefore linear functionals
 
 \citep{li2022approximation}

\paragraph{ESN}
 \citet{jaeger2001echo} proposed Echo State Networks (ESNs), demonstrating their universal approximation capabilities specifically for fading memory systems.
Fading memory refers to the property where the influence of past inputs diminishes over time, allowing the network to focus more on recent inputs while still retaining some memory of older inputs.
 Let’s clarify the role of fading memory systems in the context of infinite horizon approximations and the broader discussion on RNNs.
 
 
\paragraph{Exponential decaying memory}%
%{SMMs}
SSMs with layer-wise nonlinearity are universal approximators with exponential decaying memory \citep{wang2024state}

\citep{dubinin2024fading}

\paragraph{Uniform asymptotic incremental stability}
Uniform asymptotic incremental stability was introduced in \citep{pavlov2006uniform}.
\citep{hanson2020universal}: one can find a recurrent neural net, such that the trajectories generated by this net are arbitrarily close to the trajectories generated by the system it approximates (must be a uniformly asymptotically incrementally stable system) on an infinite time horizon.


\paragraph{Stability implies FNNs are enough}%crit
When Recurrent Models Don't Need to Be Recurrent \citep{miller2018stable}






\subsection{Topological equivalency}
Topological equivalency \citep{hart2020embedding}
This is trivial for structurally stable systems!








\subsection{Flows}
RNNs are universal approximators of flow  functions of dynamical systems  with control inputs on finite time intervals  \citep{aguiar2023}.




\subsection{Neural ODEs (NODEs)}
Neural ODEs\citep{chen2018neural} model the continuous trajectory of the hidden state \( \mathbf{h}(t) \) as the solution to an ordinary differential equation parameterized by a neural network. Mathematically, the dynamics are defined by:

\[
\frac{d \mathbf{h}(t)}{dt} = f(\mathbf{h}(t), t, \theta)
\]

where \( \mathbf{h}(t) \) is the hidden state at time \( t \), \( f \) is a neural network with parameters \( \theta \), and \( t \) represents time. Given an initial condition \( \mathbf{h}(t_0) = \mathbf{h}_0 \), the evolution of the hidden state over time is computed by solving the ODE using numerical solvers, allowing the model to capture complex, continuous transformations.

%example of f
\textbf{Fully Connected Neural Network (Feedforward Network)}:

\[
f(\mathbf{h}(t), t, \theta) = W_2 \sigma(W_1 \mathbf{h}(t) + \mathbf{b}_1) + \mathbf{b}_2
\]

Here, \( \sigma \) is an activation function (e.g., ReLU, tanh, or sigmoid), \( W_1, W_2 \) are weight matrices, and \( \mathbf{b}_1, \mathbf{b}_2 \) are bias vectors.
 This form models the ODE dynamics using a simple two-layer feedforward network.



\paragraph{Applications}
%NODEs in neuroscience%
Neural ordinary differential equations (NODEs) are being increasingly adopted in computational and systems neuroscience, showing improved performance compared to current approaches \citep{kim2021inferring,geenjaar2023learning,sedler2023expressive,elgazzar2024universal}.

%\paragraph{Latent}
Latent ODE-RNN  \citep{rubanova2019latent}

Latent ODE-LSTM \citep{coelho2024enhancing}


\paragraph{Theoretical Guarantees for Dynamical Systems}
 Proofs of Universal Approximation for Dynamical Systems
 
 Any finite trajectory of an $n$-dimensional continuous dynamical system can be approximated by the internal state of the hidden units and $n$ output units of an Liquid time-constant (LTC) network \citep{hasani2018liquid}.
 
control \citep{tabuada2020universal}

\citep{zhang2020approximation}

\citep{li2022deep}

Universal approximation of dynamical systems by semi-autonomous NODEs \citep{li2024universal}








\section{Approximation of dynamical systems on infinite time intervals}

\subsection{The problem of approximation} %{Problem statement}
For behaving agents we can formalize their behavior as sequence-to-sequence or input-output mappings.
We will call $\mathcal{X}$ the space of input sequences and $\mathcal{Y}$ the space of output sequences.

We consider a family of target functions, or simply targets, which is a subset \(\mathcal{C} \) of all mappings \( \mathcal{X} \rightarrow \mathcal{Y} \), i.e., \( \mathcal{C} \subset \mathcal{Y}^\mathcal{X} \). 
These are the relationships we wish to approximate (or ``learn"), by some (simpler or at least parameterized) candidate functions.
Let us denote this set of \textbf{candidates} by \( \mathcal{H} \subset \mathcal{Y}^\mathcal{X} \).
In learning theory, this is often called a \textbf{hypothesis space}.
The problem of approximation concerns how well functions in \( \mathcal{H} \) can resolve functions in \( \mathcal{C} \).
This is typically formulated in terms of a bound on the (maximal) error between the approximation and the target mapping.

We will discuss what the space is of target dynamical systems that we can approximate.
Furthermore, these can be approximated in a particular way, i.e. with a specific difference between the approximant and the target system (the metric).
This difference is measured as the expectation of the uniform norm difference between the flows. 
We can make the probability of finding a trajectory of the approximation to be off by a certain arbitrary threshold arbitrarily small. 


\subsubsection{Targets}
Autonomous
Structurally stable+Fixed points = hyperbolic fixed points
The dynamics is globally attractive / There exist a compact set that with the fixed points inside that is forward invariant 

\begin{equation}
\dot x = f(x)
\end{equation}
$f\in C^1$.



Later: Limit cycles (or just one?)



Different metric: Chaotic orbits
mention: we can guarantee finite time approximation
prove: we can never do infinite time approximation 


This is a Bernstein-type result (in the classification of approximation result types made in \citep{jiang2023brief}).


\subsubsection{Hypothesis class}
The hypothesis class $\mathcal{G}$ is composed of
\begin{equation}
\dot x = g(x) 
\end{equation}
where $g$ is an FNN with the universal approximation property.


\subsubsection{Metric}

Uniform norm over time (given the same initial starting point)
\begin{equation}
\|\varphi(t,x_0)-\hat \varphi(t,x_0)\|_\infty = \sup_t|\varphi(t,x_0)-\hat \varphi(t,x_0)|
\end{equation}

We consider a compact $X$ on which we measure the difference between the target and our approximation.
\footnote{FNN approximation universality is also on compact intervals.}

Expectation of the error over all initial points
\begin{equation}
%\|\varphi-\hat \varphi\|_\epsilon \coloneqq \frac{1}{\vol X}\mathbb{E}\left[ \int_{x_0\in X}   \mathds{1}[\|\varphi(t,x_0)-\hat \varphi(t,x_0)\|_\infty>\epsilon]\right],
\|\varphi-\hat \varphi\|_\epsilon \coloneqq  \mathbb{P}\left(\|\varphi(\cdot,x_0)-\hat \varphi(\cdot,x_0)\|_\infty>\epsilon\right),
\end{equation}
where $\mathds{1}[\cdot]$ is the indicator function. 
This is similar to the metric in \citep{hammer2000approximation}.


%why we cannot stricten the metric
For a multistable system it is not possible to find a universal approximation result if we consider a more strict notion of difference between the target and approximant.
For example, if we take the uniform norm of the uniform norm, it can be shown that there is always a system with a separatrix that can not be exactly matched which would lead to an error that is the distance between the two $\omega$-limit sets.

\subsubsection{Guarantee in $N\rightarrow\infty$ or at finite $N$}
It could be that existing theorems could be interpreted that in the limit $N\rightarrow\infty$ the approximation holds. %e.g.\citep{podlaski2024approximating}
ie $\lim_{N\rightarrow\infty} error = 0$
Here we do it for finite $N$.
ie for each $\epsilon>0$ $\exists N$ such that $error(N) < \epsilon$
(implies the above limit)


\subsection{Theorem}
\begin{theorem}
Let $D$ be an open subset of $\mathbb{R}^n$, $f\colon D \to \mathbb{R}^m$ be a $C^1$-mapping, and $I$ be a compact subset of $D$ such that any solution $x(t)$ with initial value $x(0) \in I$ of an ordinary differential equation
\begin{equation}\label{eq:5}
    \dot{x} = f(x), \quad x(0) \in K
\end{equation}
is defined for $t\in\reals_{+}$ and $x(t)$ is included in $I$.
This defines a flow $\varphi(\cdot, \cdot)$.


 Then, for an arbitrary $\epsilon, \delta > 0$, there exist an MLP recurrent neural network 
 \begin{equation}
\dot x = \hat f(x) = \sigma(A\sigma(Bx+b)+a)
\end{equation}
%such that for a solution $\hat \varphi(t,x_0)$ satisfying Eq~\ref{eq:5} with initial state $x_0$ of the network
such that its flow $\hat \varphi$ satisfies
\begin{equation}
\|\varphi-\hat \varphi\|_\epsilon < \delta.
\end{equation}
\end{theorem}


\begin{proof}
Because of the density of the hypothesis class $\mathcal{G}$ we have that for any $f\in C^1$ and any $\delta_1>0$
there exists $\hat f\in\mathcal{G}$ such that 


Structural stability implies that there exists a $\delta_2>0$ such that for all $g$ that are $\delta_2$ $C^1$ close to $f$ the flow is topologically equivalent to that of $f$.

So we can choose $\delta = \min\{\delta_1,\delta_2\}$ such that the flow of $\hat f\in\mathcal{G}$ is topologically equivalent to that of $f$.


Note that the above error bound depends on two separate quantities: the local error 
$\| f(s; \tilde{\varphi}_0, s(x)) - f(s; \tilde{\varphi}_0, s(x)) \|$ 
 and the term 
$\| D\varphi_{s,t}(\tilde{\varphi}_0, s(x)) \|$, 
which bounds the sensitivity of the flow $\varphi_{s,t}(x)$ to an infinitesimal perturbation of its initial condition.



%%%
We can bound these two types of errors:%error^I and error^II
\paragraph{Errors inside a the intersection of the Basins of Attraction (BoA) of the target systems and the approximation}
So if we have $x_0\in BOA(A_i^f) \cap BOA(A_i^g)$, the flow deviates along the trajectories up to 
\[
\|\varphi_{0,t}(x) - \tilde{\varphi}_{0,t}(x)\| \leq \int_0^t \|D\varphi_{s,t}(\tilde{\varphi}_{0,s}(x))\| \|f(s; \tilde{\varphi}_{0,s}(x)) - f(s; \tilde{\varphi}_{0,s}(x))\| \, ds.
\]
Prop.~\ref{prop:313} from \citep{vanhandel2007filtering}, see Supp.Sec.~\ref{sec:313}.





\paragraph{Errors at the boundary of a BoA}%type II
The other type of error arises because trajectories go to different attractors, i.e., $x_0\in BOA(A_i^f,A_j^g)$ for $i\neq j$.
For such initial points the error along the flow cannot be bounded.
Eliminating this type of error would constitute perfectly matching the separatrices which can not be guaranteed.
We can reduce the volume in of initial points for which this type of error arises, by reducing the mismatch between the separatrices (proportional to the distance between the attractors).

The volume for which type II error arises is 
\[\sum\boa(A_i^f)\cap\boa(A_i^g).\]

The boundary of the BoA of attractor $A_i^f$ is %BoAs are open sets
\[\partial\boa(A_i) = \cl\boa(A_i^f)\cap A_i^f.\]

Then for some value $\epsilon_{\operatorname{sep}}$ we have that 
\[\bigcup_i \boa(A_i^f)\cap\boa(A_i^g) \subset \bigcup_i B_{\epsilon_{\operatorname{sep}}}(\partial\boa(A_i^f)). \]

The right hand side's volume is at most $\mathcal{O}(\delta)$ with $\leq\epsilon_{\operatorname{sep}}$ the Hausdorff distance between the total separatrix submanifolds.
This $\delta$ can be made arbitrarily low because of the FNN universal approximation results.

%
For each pair $i\neq j$ the connected component of $\sep(A_i,A_j)$ is a normally hyperbolic invariant manifold (repellent). 
%(this follows from structural stability)
%for the extension of continuous attractors we need to assume that all maximally invariant sets are normally hyperbolic
For example,  all invariant manifolds of ReLU RNNs are either continuous attractors (in the direction of non-normal hyperbolicity) or normally hyperbolic.
%
Therefore, by Fenichel's Persistent manifold theorem, there exists a $\delta_{ij}$ such that for all $g$ that are $\delta_{ij}$ $C^1$ close to $f$ such that $g$ has an normally hyperbolic invariant manifold that is diffeomorphic to and at most at $\mathcal{\delta_{ij}}$ Hausdorff distance from $\sep(A_i,A_j)$.


%simplifying?
%we can consider $\cl\boa(A_i) to be an invariant manifold with boundary
%is it normally hyperbolic?


Now we need to sum all the different errors together.
\end{proof}



\setlength\belowcaptionskip{-5ex}
\begin{SCfigure}[10][bthp]
  \centering
  \includegraphics[width=0.5\textwidth]{separatrices}
  \caption{
	A mismatching pair of separatrices between attractors $A_i$ and $A_j$.
	
  }\label{fig:separatrices}
\end{SCfigure}




\subsection{Approximating a limit cycle}
We will get convergence onto a limit cycle that is close in Hausdorff distance to the target limit cycle. %$\omega$-limit set?
But, for an approximation of the vector field we will in general have a small discrepancy in the periods between the two limit cycles that will lead to a uniform norm difference between the flows that is the maximal distance between all pairs of points on the two limit cycles.
This would make our method fail!

However, we can correct this discrepancy.
We have a difference in period $T-\hat T = \delta$
with \[T\coloneqq\frac{1}{\int_{LC}\|f(x)\|dx} \text{ and } \hat T\coloneqq\frac{1}{\int_{\hat{LC}}\|\hat f(x)\|dx}.\]
%
We will apply a perturbation $\hat{\hat{f}}$ to our approximations that is small enough for the persistence of the limit cycle ($\delta$ needs to be small enough) 
so that 
\[\int_{\tilde{LC}}\|\tilde{f}(x)\| dx = \frac{1}{T}	\] for the integrated vector field along the limit cycle $\int_{LC}f(x)$.

the resulting total approximation is $\tilde{f}=\hat{f}+\hat{\hat{f}}$.

We can use the fact that the tubular neighborhood around the limit cycle (LC) is an (inflowing) normally hyperbolic invariant manifold.
This implies that there is a 3 layer FNN that approximates the vector field x a bump function around the LC (similar idea as in paper but this would be an actual possible implementation).
Then we know that the this NHIM will persist.
We also know that there is a maximal perturbation size ($\epsilon_{LC}$) for which the limit cycle persists.
So we have to guarantee that the limit cycle approximation is already close enough so that this perturbation does not destroy the limit cycle.
We can now rescale the perturbation so that the period of approximation limit cycle matches the target's. 
We just increase or decrease  the above perturbation by multiplying with a scalar so that this equality holds.
The only thing we now need to worry about is how the length of the limit cycle changes as a result of this perturbation and whether we can indeed get the equality.

Fenichel's PMT guarantees that the perturbed limit cycle lies within $\mathcal{O}(\epsilon)$ the original limit cycle approximation.

%So if it gets longer because of the perturbation (i.e. $\hat \ell(\epsilon)$ is an increasing function) as long as $1/(\hat \ell+g(\epsilon))$ is not decreasing at the same rate there should exist a value $\epsilon$ for which the equality holds

%the fixed point happens at an epsilon that is small enough for the persistence of the other parts: TODO

%choosing the size of the tubular neighbourhood



%%%QPTA
\subsubsection{QPTA}%more generally: doing this for multiple limit cycles
\citep{Park2023a}


\subsection{Approximating a chaotic orbit}
We cannot approximate according to our above criteria.
Every small discrepancy in the vector field will lead to 
(analogous to perturbing initial start of the chaotic orbit 


What we can do is minimize the Hausdorff distance between the chaotic invariant manifolds and match the Lyapunov exponents of the target system
The first because of structural stability
%The second because of ??

Alternatively, we can guarantee that 


Symbolic dynamics
Mapping onto the same discrete dynamical shift dynamical system?



%%%CA
\subsection{Approximating a continuous attractors}

We can tile the continuous attractor with a uniform grid of stable fixed points.
Each of the neighbouring stable fixed points can be at most $\epsilon$ apart.
This is structurally stable dynamics, so we can approximate its vector field with $\epsilon$ accuracy and we are guaranteed to have a topologically equivalent system to it with the fixed points being moved at most $\mathcal{O}(\epsilon)$.

See \citep{Sagodi2024a}


\subsection{Input driven dynamics}

This can be only done by also calculating in the probability of making an error on a given input.
So the approximation probability guarantee will need to be formulated in terms of the probability of making an error bigger than a threshold calculated over the function of input sequences and initial points.



For non-autonomous we need another Bernstein-type result:
we can only approximate input driven dynamics (in our metric) if a forward attractor exists for each input sequence 
This allows us to formulate approximation in terms of attractors and separatrices (but now in input space)


\section{Implications for understanding neural computation}

Use of NODEs \citep{kim2021inferring}




\section{Discussion}


\paragraph{Limit cycles}
Approximable but approximation is not robust! (period will change under almost all perturbations)

\paragraph{The price of universality}
This construction is immensely inefficient

Better to just look at RNNs. 



\newpage
\bibliography{../all_ref.bib,../catniplab.bib}



\newpage
\appendix 

\section{Universal Approximation with Feedforward Neural Networks (FNNs)}

The foundation of our approach lies in leveraging the \textit{universal approximation property} of feedforward neural networks (FNNs), a powerful result that makes neural networks exceptional for a broad array of tasks. This property allows FNNs to approximate complex functions with remarkable flexibility, providing the theoretical basis for their widespread success in machine learning.

\subsection{The Universal Approximation Theorem}

The universal approximation theorem states that a \textit{feedforward neural network} with at least one hidden layer, using a non-linear activation function (such as the sigmoid or ReLU), and equipped with enough neurons, can approximate \textit{any continuous function} defined on a compact subset of \(\mathbb{R}^n\) to arbitrary precision.

Formally, for any continuous function \(f(x)\) and any \(\epsilon > 0\), there exists an FNN such that:
\[
| f(x) - f_{\text{MLP}}(x) | < \epsilon \quad \forall x \in K
\]
where \(K \subset \mathbb{R}^n\) is compact. This guarantees that given sufficient resources (neurons, depth), the FNN can approximate \(f(x)\) as closely as desired within this bounded region.

The importance of the compact domain assumption is that it constrains the input space to a finite region, ensuring the approximation remains well-behaved.
This is where the theorem’s beauty shines: while we often don’t know the explicit form of the target function, neural networks learn it purely from data, making them excellent for tasks like regression, classification, and pattern recognition.



\subsection{Activation functions} %Sigmoidal 
At the heart of the theorem lies the activation function. Any non-linear, continuous, and non-constant function enables the network to approximate continuous functions universally.
A classic example is the \textit{sigmoidal function}, defined by the property:
\[
\lim_{x \to -\infty} \sigma(x) = 0 \quad \text{and} \quad \lim_{x \to +\infty} \sigma(x) = 1
\]
Many popular activation functions, such as the logistic sigmoid and tanh, fall into this category.
These functions introduce the necessary non-linearity, enabling the network to break free from the constraints of purely linear transformations.

%non-sigmoidal activations like the \textit{Rectified Linear Unit (ReLU)} 
Despite ReLU's unbounded nature, it still supports the universal approximation property, as shown in \citep{yarotsky2017error}.



\subsection{The Multi-layer Perceptron (MLP)}

The universal approximation property of FNNs was first proven by \citep{cybenko1989approximation} for sigmoidal activation functions. This was followed by significant generalizations by \citep{hornik1989multilayer} and \citep{funahashi1989approximate}, which extended the result to broader classes of activation functions, including the popular ReLU.
These results serve as the cornerstone of modern neural network theory, supporting the use of deep architectures across diverse machine learning applications.

%all above are 3 layer FNNs? right?

Let’s now focus on the structure of a \textit{multi-layer perceptron (MLP)}, a common form of FNN. For a simple 3-layer MLP, the output can be expressed as:
\[
h^{(1)} = \sigma(W^{(1)} x + b^{(1)})
\]
\[
f_{\text{MLP}}(x) = W^{(2)} h^{(1)} + b^{(2)}
\]
Here, \(h^{(1)}\) represents the hidden layer, while \(W^{(1)}, W^{(2)}\) and \(b^{(1)}, b^{(2)}\) are the weights and biases learned during training. The activation function \(\sigma(\cdot)\) introduces the necessary non-linearity.




In a more general case, for a deeper MLP with \(L\) layers, we have:
\[
h^{(1)} = \sigma(W^{(1)} x + b^{(1)})
\]
\[
h^{(2)} = \sigma(W^{(2)} h^{(1)} + b^{(2)})
\]
\[
\vdots
\]
\[
h^{(L-1)} = \sigma(W^{(L-1)} h^{(L-2)} + b^{(L-1)})
\]
\[
f(x) = W^{(L)} h^{(L-1)} + b^{(L)}
\]

This architecture allows the MLP to progressively build complex representations, layer by layer, transforming raw input data into rich feature hierarchies.


For the approximations, we either need to let the width or depth of the MLP grow.

\section{Support for the proof}

\subsection{Fenichel's Persistent Manifold Theorem}


\subsection{Basins of attraction}
Denote the basin of attraction for an attractor $A$ as $BOA(A)$.

\begin{proposition}
\[\dim BOA(A_i) = \dim X\] for each attractor $A_i$.
\end{proposition}

\begin{proposition}
\[\dim\cl BOA(A_i) \cap BOA(A_i) = \dim X - 1 \] for each attractor $A_i$.
\end{proposition}

\begin{proposition}
Each connected component of $\bigcup_i\cl BOA(A_i) \cap BOA(A_i) $ is a connected, compact normally hyperbolic invariant manifold. %repelling/outflowing?
\end{proposition}


\subsection{Separatrices}

\begin{definition}[Separatrix]\label{def:separatrix}
Define the separatrix between the basins of attraction of attractors $A_i$ and $A_j$ as 
\begin{equation}
\sep(A_i,A_j) = \cl(BOA(A_i)\cap \cl(BOA(A_j)).
\end{equation}
\end{definition}




\subsection{In basin bound}\label{sec:313}
\begin{proposition}[Proposition 3.1.3. in \citep{vanhandel2007filtering}]\label{prop:313}
Define 
\[
\frac{d x(t)}{d t} = f(t; x_t), \quad x(t) \in \mathbb{R}^n.
\]
We denote by $\varphi_{s,t}(x)$ the solution $x_t$ of this equation when it is started at the initial condition $x(s) = x$ ($s \leq t$). We will suppose that $f$ is sufficiently regular so that the flow $\varphi_{s,t}(x)$ exists, is unique, and is a diffeomorphism for all $0 \leq s \leq t < \infty$.

Now consider another differential equation 
\[
\frac{d \tilde{x}_t}{d t} = \tilde{f}(t; \tilde{x}_t), \quad \tilde{x}_t \in \mathbb{R}^n,
\]
where again we assume that $\tilde{f}$ is sufficiently regular so that this equation generates a unique flow $\tilde{\varphi}_{s,t}(x)$ as above.


The following error bound holds:
\[
\|\varphi_{0,t}(x) - \tilde{\varphi}_{0,t}(x)\| \leq \int_0^t \|D\varphi_{s,t}(\tilde{\varphi}_{0,s}(x))\| \|f(s; \tilde{\varphi}_{0,s}(x)) - f(s; \tilde{\varphi}_{0,s}(x))\| \, ds.
\]
\end{proposition}



\subsection{Perturbing limit cycles}
If the limit cycle is hyperbolic, the Hausdorff distance between the original and perturbed limit cycles tends to scale linearly with \(\epsilon\), the size of the perturbation. That is,

\[
d_H(\gamma_0, \gamma_\epsilon) = O(\epsilon),
\]

where \(d_H\) denotes the Hausdorff distance. The linear dependence arises because small changes in the vector field result in small changes in the trajectories of the system, which leads to a nearby limit cycle.


\subsubsection{Applying Melnikov’s Method to Limit Cycles}

To understand the period change due to a perturbation of a limit cycle, let’s consider the following:

Suppose we have an unperturbed system
\[
\dot{x} = f(x)
\]
with a limit cycle \(\gamma_0\) of period \(T_0\).

Now we apply a small perturbation to the system:
\[
\dot{x} = f(x) + \epsilon g(x),
\]
where \(g(x)\) represents the perturbation, and \(\epsilon\) is a small parameter.

The Melnikov function \(M(t)\) measures the first-order effect of the perturbation on the limit cycle, and it is given by:
\[
M(t) = \int_0^{T_0} \langle \nabla H(x_0(t)), g(x_0(t)) \rangle \, dt,
\]
where:
\begin{itemize}
    \item \(x_0(t)\) is the trajectory along the limit cycle \(\gamma_0\),
    \item \(H(x)\) is the Hamiltonian (or energy function) associated with the unperturbed system,
    \item \(g(x)\) is the perturbation vector field,
    \item \(\langle \cdot, \cdot \rangle\) denotes the dot product.
\end{itemize}

The Melnikov function tells us how the perturbation influences the distance between stable and unstable manifolds in the phase space. It is closely related to the splitting of separatrices, but in the context of limit cycles, it helps predict changes in the period and persistence of the limit cycle.

For small perturbations:

\(M(\gamma_0)\) represents the sensitivity of the period or structure of the limit cycle to the perturbation.

If \(M(\gamma_0) \neq 0\), the limit cycle may shift slightly, but it will persist, and the change in the period can be approximated as:
\[
\Delta T \approx \epsilon M(\gamma_0),
\]
meaning that the period change is proportional to \(\epsilon\), the size of the perturbation, with \(M(\gamma_0)\) determining the proportionality constant.

If \(M(\gamma_0) = 0\), the system is at a critical point where a bifurcation may occur, and the limit cycle may undergo a qualitative change (e.g., it could disappear or bifurcate).



\subsubsection{Homeomorphism and homotopy}

A homeomorphism \( f \) between the two limit cycles is a continuous, bijective map that transforms points on \( \gamma_1(t) \) to points on \( \gamma_2(s) \) while preserving the topological structure. Mathematically, this is expressed as:
\[
f: \gamma_1(t) \rightarrow \gamma_2(s), \quad \text{where} \quad s = h(t)
\]
Here, \( h(t) \) is a continuous, bijective, and periodic function that maps the time variable \( t \) in System 1 to the time variable \( s \) in System 2, i.e.,
\[
h: [0, T_1] \rightarrow [0, T_2]
\]
with the condition that \( h(0) = 0 \) and \( h(T_1) = T_2 \).

The map \( f \) in terms of the coordinates can be written as:
\[
f(x_1(t), y_1(t)) = (x_2(h(t)), y_2(h(t)))
\]



The homotopy \( H \) between two limit cycles \( \gamma_1(t) \) and \( \gamma_2(t) \) is expressed as:
\[
H: [0,1] \times [0, T] \rightarrow \mathbb{R}^n
\]
where \( H(\tau, t) \) gives the position of a point on the limit cycle at time \( t \) and for a given \( \tau \). The transformation satisfies:
\[
H(0, t) = \gamma_1(t), \quad H(1, t) = \gamma_2(t)
\]
This means that at \( \tau = 0 \), the homotopy corresponds to the first limit cycle \( \gamma_1 \), and at \( \tau = 1 \), the homotopy corresponds to the second limit cycle \( \gamma_2 \). For intermediate values of \( \tau \), \( H(\tau, t) \) represents a continuous deformation between \( \gamma_1 \) and \( \gamma_2 \).


\end{document}