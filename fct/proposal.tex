\documentclass[12pt,letterpaper, onecolumn]{article}
%\documentclass{article}
%\documentclass{scrartcl}
\usepackage[left=1.2cm, right=1.2cm,top=1.5cm,bottom=1.5cm]{geometry}
\usepackage[utf8]{inputenc}
\usepackage{titling}\setlength{\droptitle}{-1em}   % This is your set screw
\usepackage{amssymb, amsmath, amsthm}
\usepackage{thmtools, mathtools, mathrsfs}
\usepackage{amsfonts}
%\usepackage[sort&compress,numbers]{natbib}
%\usepackage[round,sort&compress,numbers]{natbib}
\usepackage[%
  giveninits=true,
  backend=bibtex,
  doi=false,
  isbn=false,
  url=false,
  natbib,    
]{biblatex}
\AtEveryBibitem{%
  \clearfield{pages}%
}
\renewcommand{\bibfont}{\normalfont\footnotesize}
\usepackage{subcaption}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{float}
\usepackage{bm}
\usepackage{tikz}
\usetikzlibrary{positioning,matrix,arrows,decorations.pathmorphing}
\usepackage{tikz-cd} 
\usepackage{etoolbox}

\definecolor{processblue}{cmyk}{0.8,0,0,0}
\definecolor{mpcolor}{rgb}{1, 0.1, 0.59}
\newcommand{\mpcomment}[1]{(\textbf{MP:\ }\textcolor{mpcolor}{#1})}

\newtheorem{theorem}{Theorem}
\newtheorem{prop}{Proposition}
\theoremstyle{definition}
\newtheorem{definition}{Definition}
\theoremstyle{remark}
\newtheorem{remark}{Remark}
 \usepackage{thmtools, thm-restate} \newtheorem{conjecture}[theorem]{Conjecture}

\newcommand{\reals}{\mathbb{R}}
\newcommand{\mb}[1]{\mathbb{#1}}
\newcommand{\mc}[1]{\mathcal{#1}}
\DeclareMathOperator{\Inv}{Inv}
\DeclareMathOperator{\innt}{int}
\newcommand{\probP}{\text{I\kern-0.15em P}}
 
 \addbibresource{ref.bib}
 \addbibresource{catniplab.bib}
\defbibenvironment{bibliography}
  {\noindent}
  {\unspace}
  {\printtext[labelnumberwidth]{%
    \printfield{labelprefix}%
    \printfield{labelnumber}}
    \addspace}
\renewbibmacro*{finentry}{\finentry\addspace}

%\title{A framework for Infinite Horizon Neural Computation} %on Compact Domains

\begin{document}
%\maketitle

\begin{center}
%\LARGE{\textbf{A for infinite horizon neural computation}}
\LARGE{\bf An infinite-horizon language for neural computation}
\end{center}
\begin{center}
{\textbf{\'Abel S\'agodi}}
\end{center}

\section*{Abstract}
The neural system, comprised of interconnected neurons with limited capacity, orchestrates essential cognitive processes such as perception, decision-making, and motor control by integrating sensory information with short-term memory. Understanding these processes at an algorithmic level is pivotal for unraveling the fundamental principles governing neural function. Dynamical systems theory, particularly the concept of stable fixed points, provides a formal framework for describing information processing in the brain. Continuous attractors, networks with a continuum of fixed points, have emerged as models for representing continuous variables like spatial locations, head direction, and motor commands. 
Working memory, crucial for temporary storage and manipulation of information, relies on (continuous) attractor network dynamics to sustain persistent neural activity, ensuring stability against distractions and noise. However, theoretical models often lack this robustness observed in biological networks.
In this project, we propose a novel framework aimed at describing neural computation while capturing the robustness properties observed in biological networks. By extending existing reverse engineering approaches for neural dynamics, we will characterize how artificial neural networks compute and generate behaviors and compare it to neural dynamics in animals. This endeavor holds promise for advancing our understanding of neural function and information processing, bridging the gap between theoretical models and biological reality.

Animals have 

\newpage
\section{State of the art}
The neural system is a complex network consisting of units of limited capacity, neurons.
As a whole, it can process immediate sensory information and integrate it with short-term memory to produce essential survival behaviors such as perception, decision-making, and motor control.
The challenge of understanding these cognitive processes at an algorithmic or information-processing level is one of the primary goals in computational and theoretical neuroscience \citep{zoltowski2020general, pagan2022, whiteway2019, dyer2023simplest}.
Such an investigation is pivotal for revealing the fundamental principles that govern neural function and advancing our understanding of the neural basis of cognition and information processing in general.

The literature extensively employs concepts from dynamical systems theory to formally describe the algorithmic essence of information processing in the brain \citep{vyas2020computation}.
At the heart of current approaches lies the notions of ``stable fixed points,'' which represent the brain's internal states that remain consistent over time despite small perturbations.
The (stable) fixed points are extremely useful since they can maintain discrete states in neural systems for arbitrarily long times, where each neuron tends to forget the past within a few hundred milliseconds. % for timescales of seconds with neurons and synapse transmission operating mostly on time scales of tens of milliseconds and shorter
Networks with a continuum of fixed points, known as continuous attractors \citep{fung2010, khona2022, wu2008, wu2016}, have been proposed as models for representing continuous variables such as spatial locations \citep{samsonovich1997, stringer2002placecells, yang2022, wimmer2014, guanella2007model, gardner2022toroidal}, head direction \citep{stringer2002headdirection, hulse2020, turner2017, turner2020neuroanatomical, vafidis2022, kim2019generation}, motor commands \citep{stringer2003} and for the representation of other internal states \citep{nair2023, branco2016}.

%Animals gather information about their surroundings through sensory modalities such as vision, audition, olfaction, and touch. Neuroscientists study how the brain processes these sensory inputs to build representations of the environment. For instance, during spatial navigation, the brain combines visual landmarks, sounds, and scents to construct a cognitive map of the environment. Efficient navigation involves decision-making, where animals assess different sensory cues, evaluate risks and rewards, and plan routes to enhance their survival chances.
%
%Dynamical systems approaches in the context of neural computation and information processing aim to understand the behavior of neural systems by modeling them as sets of differential equations. In this framework, the state of a neural system is described by a set of variables, typically representing the activity levels of individual neurons or neural populations. These variables evolve over time according to the dynamics specified by the differential equations. 

Working memory involves the temporary storage and manipulation of information over short time scales. The dynamics of an attractor network sustain persistent neural activity, maintaining the representation of the stored information in working memory, e.g., integrating angular velocity to update the head direction representation \citep{barak2013, barak2014, durstewitz2000, wolpert1995, goncalves2014, burak2009, goldman2007, aksay2007, noorman2022, cueva2021a, cueva2021b}. Neural function is robust to noise \citep{faisal2008}, ensuring the stability of the working memory representation \citep{koulakov2002} in biological networks \citep{gallego2020}, yet this robustness is lacking in many theoretical models \citep{renart2003, seeholzer2019, machens2008}.
The function of working memory has been modeled involving neural populations representing options in decision-making tasks \citep{gold2007neural}, where the decision is reached when one population reaches a threshold level of activity or by comparing the dynamics of competing populations \citep{wong2007, wong2008, hocker2024, esnaola2022flexible}.

To understand how artificial neural networks compute and generate behaviors, accessing the underlying neural states and reverse engineering their temporal evolution is crucial. This approach can be applied to task-based modeling, where RNNs are trained to mimic cognitive functions observed in the brain \citep{darshan2022, barak2017recurrent, durstewitz2023reconstructing, yang2019task, yang2019multiple, yang2020artificial, jarne2023b, song2016}. This method can give insight into the possible computational principles underlying brain regions' operations. This analysis is challenging for large networks because of their black-box nature \citep{lipton2018, erasmus2021}.


One method for reverse engineering neural dynamics, fixed point analysis, simplifies complex global features of neural activity by examining stable fixed points \citep{sussillo2013blackbox, sussillo2014, beer2018, maheswaranathan2019universality, driscoll2022, mante2013context}. However, it is limited to systems with a finite set of stable fixed points. Recently, limit cycles have been explored, showing promise in understanding RNN dynamics \citep{pals2024}. Slow manifolds, capturing multi-scale dynamics, also hold potential. Integrating insights from limit cycles and slow manifolds into computational models could offer a more comprehensive framework for studying neural computation.



%Most, if not all, theories of recurrent neural computation are described using dynamical systems theory. Most theories were built on carefully designed systems to implement a computation, i.e., an input-output mapping. The most often used feature is the fixed point, i.e., a neural population state that remains constant over time. Networks with a continuum of fixed points, i.e., a continuous attractor, have been used to explain how the brain might represent continuous variables, such as the head direction and the location of the animal \citep{stringer2002headdirection, stringer2002placecells}.
%
%These models are remarkably delicate; even a minuscule change to the parameters (synaptic weights) can cause the continuum of fixed points to vanish (this property is called structural stability). This fragility underscores the challenge of understanding how biological neural networks, existing in a constantly changing and noisy biological substrate, perform under such conditions. Our current understanding of stability falls short in adequately capturing the intricacies of neural dynamics and their resilience to perturbations. 
%
%More generally, it is necessary to access the underlying neural states and reverse engineer their temporal evolution to understand how artificial neural networks or latent variable models compute and generate meaningful behaviors. Reverse engineering of dynamical systems descriptions of the brain has been applied to Recurrent neural networks (RNNs). Task-based modeling with RNNs has emerged as a popular way to infer the computational function of different brain regions to model large-scale neural recordings directly \citep{sussillo2014, barak2017recurrent}.
%
%Nevertheless, reverse engineering RNNs poses significant challenges \citep{marom2009}. RNNs often operate in high-dimensional spaces, which can complicate the analysis and interpretation of their internal representations and dynamics. Furthermore, RNNs often lack interpretability \citep{erasmus2021}, meaning that it can be hard to understand why they make particular predictions or produce certain outputs.
%
%One approach for this reverse engineering, fixed point analysis, assumes that the overall arrangement of fixed points of the dynamics can provide a simple and comprehensive explanation for the complex global features of neural activity observed in the system \citep{sussillo2013blackbox, maheswaranathan2019universality, beer2018}. We believe these issues have not been adequately addressed in models that describe neural computation. Fixed point analysis is only applicable to systems with a finite set of stable fixed points. Recently, limit cycles have been considered in the analysis. Limit cycles offer some promise in enhancing our understanding of the dynamics of RNNs, but further research is needed to fully explain their roles in neural computation. Furthermore, the concept of slow manifolds, which capture the dynamics of systems evolving on multiple time scales, holds promise in further enriching our understanding of RNNs and their computational properties. Integrating the insights gained from limit cycles and slow manifolds into computational models of neural networks could offer a more comprehensive framework for studying the complex dynamics of neural computation.
%
%The existing language used in theoretical neuroscience to describe neural computation is inadequate. We propose a new language specifically designed to articulate the complexities of working-memory type neural computation that can correctly describe the stability of the system yet provides an interpretable description of the computation. 


\newpage
\section{Objectives}
The overarching objective of this project is to develop a more suitable mathematical language for understanding neural computation. In particular, we want a unifying framework to describe working memory type neural computation that encompasses the robustness properties of biological neural networks.

\subsection*{Aim 1: Developing a language for robust neural computation}
Theoretical neuroscientists today face a challenge - the lack of a  framework that accurately reflects the robustness of biological neural networks while being easily interpretable \citep{lillicrap2019}.
We propose a framework that relies on describing memory in terms of slow manifolds \citep{ghazizadeh2021slow} and robust asymptotic dynamics \citep{casey1996}.
These structures provide a description of the memories and their decay at a range of timescales \citep{jaeger2023timescales} and allow for coarsening (via the nesting of attractors) \citep{braun2010}.
We prove that these structures are robust to noise in the parameters \citep{Park2023a} and that they provide a general way for approximating continuous attractors.
This framework will allow us to describe the various ways the brain might implement working memory-type computation with a biological level of resilience.
%Finally, we propose a coarsening of the description through an equivalence via the output mapping.


\subsection*{Aim 2: Describing the implemented neural computation through recurrent sets}
Designed models for neural computation are naturally easy to frame in the above language, but for trained RNNs or fitted models to neural data, the mechanism of the computation needs to be extracted. We will extract the implemented computation through three primary components of analysis. Firstly, we identify the recurrent sets and slow manifolds of the system that represent that correspond to meaningful input sequences or outputs, i.e., we implement a follow the attractor rule. Secondly, we describe how the input drives the network between these recurrent sets and implements the computation algorithm. Lastly, based on the output mapping of the recurrent sets, we extract the semantic meaning.
This analysis is much more broadly applicable than existing approaches \citep{sussillo2013blackbox, sussillo2014, beer2018, maheswaranathan2019universality, driscoll2022, mante2013context, turner2021charting, turner2023, casey1996, valente2022extracting}.

\subsection*{Aim 3: Comparison of trained RNNs and neural activity from trained animals}
We employ the developed analysis technique across various tasks, examining both Recurrent Neural Networks (RNNs) trained on the tasks and Neural ODEs (NODEs) fitted to neural activity recorded from animals trained on the same tasks \citep{zhao2016, pandarinath2018inferring, kim2021inferring}.
 Our analysis spans several tasks, including the Poisson clicks task \citep{brunton2013rats},
  the delayed match-to-category task \citep{chaisangmongkon2017computing},
  memory guided saccade task \citep{wimmer2014},
  and context-dependent sensory integration task \citep{mante2013context}.
   Through this comprehensive approach, we aim to gain insights into the neural dynamics underlying these diverse cognitive processes, shedding light on both the computational mechanisms employed by artificial neural networks and the neural substrates utilized by biological organisms during task performance.



\newpage
\section{Detailed description}
\subsection*{Aim 1}
%We propose a framework that relies on describing memory in terms of slow manifolds \citep{ghazizadeh2021slow} and robust asymptotic dynamics \citep{casey1996}.
%These structures provide a description of the memories and their decay at a range of timescales \citep{jaeger2023timescales} and allow for coarsening (via nesting attractors) \citep{braun2010}.
%We prove that these structures are robust to noise in the parameters \citep{Park2023a} and that they provide a general way for approximating continuous attractors.
%This framework will allow us to describe the various ways the brain might implement working memory-type computation with a biological level of resilience.

\subsubsection*{Aim 1.1: We formulate a general framework for memory in neural networks}
%Constraints for the language

We develop a framework for memory components in neural networks.
Learning long-term dependencies with gradient descent is difficult, because of negative Lyapunov exponents \citep{bengio1994learning, orvieto2023b}.
%\citep{soo2023}
The only two ways of maintaining a memory for arbitrarily long intervals are continuous attractors and quasi-periodic toroidal attractors \citep{Park2023a}.
We will focus on continuous attractors. %why?

The memory in biological networks is robust to minimal levels of both S- and D-type noise \citep{Park2023a}.
S-type or ``fast noise'', is caused by noisy components as the stochasticity of neuronal spiking, and is characterized by perturbations to the state \citep{panichello2019, burak2012}.
This is problematic for structures such as saddle nodes, as an arbitrary small perturbation can lead to .
D-type or``frozen noise'', is caused by continually changing synaptic weights \citep{flesch2023continual}, and is characterized by perturbations to the eqations that describe the dynamics \citep{seeholzer2019, laje2013, flesch2022}.
In particular for CANNs, D-type noise is problematic, as it makes the state drift away from its initial position in a directed manner, destroying the ability to represent a continuum of states.


%Levels of abstraction
On the highest level of abstraction of the dynamics of the system, we will still refer to the biologically irrelevant continuous attractors to explain brain function, but in this new framework these will be connected to the biologically relevant approximations the brain actually might use.
We prove that all hyperbolic continuous attractors are surrounded by dynamical systems that have a slow invariant manifold that is diffeomorphic to the attractor. This implies that for example normally hyperbolic ring attractors are surrounded in the space of dynamical systems by systems with an attractive slow invariant manifold that is composed on stable and saddle nodes and connecting orbits between them.
%There are various approximations that the brain might use to approximate such structural instability of theoretical models. For example, a line attractor can be approximated with fixed points  or a slow flow, between stable and unstable fixed point \citep{haviv2019, pollock2020}.




%Robustness ananlysis
%Projection of dynamics onto the attractor manifold \citep{seeholzer2019}
%
Sufficient robustness to allow for homeostasis \citep{oleary2018homeostasis, niemeyer2021, kozachkov2022a, seeholzer2019}.
%Short-term facilitation and depression on noise-induced memory degradation in one-dimensional continuous attractor models \citep{seeholzer2019}



\subsubsection*{Aim 1.2: Analysis of robustness properties of continuous attractors}
 We analyze the following models of ring attractors: \citep{pollock2020, barak2021mapping, beiran2021, noorman2022}.
We assess their robustness in the following ways:
the shortest distance to a perturbation that destroys the attractive slow invariant manifold,
the probability of a fixed size perturbation that destroyes the continuous attractor,
the amount of mainained memories on the destroyed continuous attractor,
the average increase in speed as a function of the perturbation size.





Deliverable: benchmark for robustness of models of neural integration







\subsection*{Aim 2}
The scope of the covered neural computation involves working memory type computation with a long-term component. Examples encompass neural integration, evidence accumulation, and decision-making.
What kinds of dynamical behavior a given network exhibits was analyzed for small systems \citep{beer1995ctrnn, beer1995interaction, beer1995computational, beer2006, beer2023}. % and Jaeger \citep{jaeger2021, jaeger2023theory} have been explored thus far.


We will extract the implemented computation, defined as an input-output mapping, through three primary analysis components.
%Encoding, past
we identify the system's recurrent sets and slow manifolds that correspond to meaningful input sequences or outputs \citep{goudar2018}. This approach is a generalization of the ``follow the fixed point rule'' and we call it the ``follow the attractor rule''. We implement this by computing the Morse decomposition of a network from the numerically integrated trajectories relevant to the task \citep{mischaikow1999, arai2009database}.
%Decoding, future
Secondly, we describe how the input drives the network between these recurrent sets by calculating the basins of attraction and determining the $\omega$-limit cycles for the autonomous dynamics after a sequence of inputs with the network initialized at a recurrent set. We do this at different timescales by separating the system into slow and fast components, which allows us to construct slow manifolds as well \citep{jones1995, kuehn2015, casey1996}.
%Timescales
We determine how constraints on the time window or time scale used to assess the correspondence in the implemented computation in terms of the input-output relationship contribute to these different kinds of approximation.


Lastly, based on the output mapping of the recurrent sets, we extract the behavioral-semantic meaning by identifying the output mapping of all the recurrent sets and slow manifolds. Furthermore, the same output can elicited by different activity patterns in different behaviors or contexts, and we, therefore, group recurrent sets according to a metric in the output space \citep{athalye2023, myers2022}.
Timescale and grouping through the output mapping allow for the coarsening of representation of the implemented computation via the merging of attractors \citep{braun2010}.
The coarsening provides interpretability, as we can coarsen the memory states to a suitable simplicity.

%comparison


Deliverable: Open-source analysis tools for automated model identification and simplification.




%Universality of Linear Recurrences Followed by Nonlinear Projection \cite{orvieto2023a}
%CTRNNs \citep{funahashi1993approximation}





\subsection*{Aim 3}

By comparing trained RNNs on various tasks and neural dynamics, we can gain insight into the neural implementations of integration and decision making. If you're interested in understanding these processes better, exploring this approach could be a valuable use of your time.



\subsubsection*{Aim 3.1: training RNNs on analogous tasks.}
We analyze RNNs trained with the backpropagation through time \citep{farrell2022, schuessler2020}.
We use, i.e., mean-squared error loss for the memory-guided saccade task and cross-entropy for the Poisson clicks task.
We give extra attention to the long-term aspect of memory maintenance, which we enforce through gradient flossing \citep{engelken2023b} and equilibrium propagation \citep{laborieux2023}.





\subsubsection*{Aim 3.2: Fitting dynamical systems to neural recordings.}

%Datasets.
For this aim, we leverage various datasets, including recordings from the rat brain motor cortex (for tasks like Poisson clicks and context-dependent decision-making) and data from experiments with rhesus and Macaque monkeys (for tasks like memory-guided saccades and delayed match-to-category tasks).

 

%Methods
We compare different methods to fit dynamical systems to neural data \citep{zhao2016}:
 Neural ODEs (NODEs) fitted \citep{kim2021inferring},
 seq-VAEs \citep{pandarinath2018inferring},
dynamical systems reconsttruction \citep{schmidt2019}.





%Comparisons
\subsubsection*{Aim 3.3: Identifying mechanisms of neural computation}
We aim to identify the underlying mechanisms of neural computation by comparing trained RNNs with fitted models based on neural recordings.  One will be based on the Morse-Conley decomposition that identifies correspondece of the topological structure of recurrent sets and connecting orbits \citep{arai2009}. The other will be based on topological conjugacy \citep{ostrow2024beyond}.
We identify the best corresponding RNN for each task and dataset as an explanation of how the brain implements different kinds of decision-making \citep{levenstein2023}.
 


Deliverable:  Comprehensive insights into the neural implementations of integration and decision-making, derived from the analysis of trained RNNs on analogous tasks and fitting dynamical systems to neural recordings.

\newpage
\printbibliography

\end{document}
