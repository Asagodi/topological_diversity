\documentclass[12pt,letterpaper, onecolumn]{article}
%\documentclass{article}
%\documentclass{scrartcl}
\usepackage[left=1.2cm, right=1.2cm,top=1.5cm,bottom=1.5cm]{geometry}
\usepackage[utf8]{inputenc}
\usepackage{titling}\setlength{\droptitle}{-1em}   % This is your set screw
\usepackage{amssymb, amsmath, amsthm}
\usepackage{thmtools, mathtools, mathrsfs}
\usepackage{amsfonts}
%\usepackage[sort&compress,numbers]{natbib}
%\usepackage[round,sort&compress,numbers]{natbib}
\usepackage[%
  giveninits=true,
  backend=bibtex,
  doi=false,
  isbn=false,
  url=false,
  natbib,    
]{biblatex}
\AtEveryBibitem{%
  \clearfield{pages}%
}
\renewcommand{\bibfont}{\normalfont\footnotesize}
\usepackage{subcaption}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{float}
\usepackage{bm}
\usepackage{tikz}
\usetikzlibrary{positioning,matrix,arrows,decorations.pathmorphing}
\usepackage{tikz-cd} 
\usepackage{etoolbox}

\definecolor{processblue}{cmyk}{0.8,0,0,0}
\definecolor{mpcolor}{rgb}{1, 0.1, 0.59}
\newcommand{\mpcomment}[1]{(\textbf{MP:\ }\textcolor{mpcolor}{#1})}

\newtheorem{theorem}{Theorem}
\newtheorem{prop}{Proposition}
\theoremstyle{definition}
\newtheorem{definition}{Definition}
\theoremstyle{remark}
\newtheorem{remark}{Remark}
 \usepackage{thmtools, thm-restate} \newtheorem{conjecture}[theorem]{Conjecture}

\newcommand{\reals}{\mathbb{R}}
\newcommand{\mb}[1]{\mathbb{#1}}
\newcommand{\mc}[1]{\mathcal{#1}}
\DeclareMathOperator{\Inv}{Inv}
\DeclareMathOperator{\innt}{int}
\newcommand{\probP}{\text{I\kern-0.15em P}}
 
 \addbibresource{ref.bib}
 \addbibresource{catniplab.bib}
\defbibenvironment{bibliography}
  {\noindent}
  {\unspace}
  {\printtext[labelnumberwidth]{%
    \printfield{labelprefix}%
    \printfield{labelnumber}}
    \addspace}
\renewbibmacro*{finentry}{\finentry\addspace}

%\title{A framework for Infinite Horizon Neural Computation} %on Compact Domains

\begin{document}
%\maketitle

\begin{center}
%\LARGE{\textbf{A for infinite horizon neural computation}}
\LARGE{\bf An infinite-horizon language for neural computation}
\end{center}
\begin{center}
{\textbf{\'Abel S\'agodi}}
\end{center}

\section*{Abstract}



\section{State of the art}
The neural system is a complex network consisting of units of limited capacity, neurons.
As a whole, it can process immediate sensory information and integrate it with short-term memory to produce essential survival behaviors such as perception, decision-making, and motor control.
The challenge of understanding these cognitive processes at an algorithmic or information-processing level is one of the primary goals in computational and theoretical neuroscience.
Such an investigation is pivotal for revealing the fundamental principles that govern neural function and advancing our understanding of the neural basis of cognition and information processing in general.

The literature extensively employs concepts from dynamical systems theory to formally describe the algorithmic essence of information processing in the brain.
At the heart of current approaches lies the notions of ``stable fixed points,'' which represent the brain's internal states that remain consistent over time despite small perturbations.
The (stable) fixed points are extremely useful since they can maintain discrete states in neural systems for arbitrarily long times, where each neuron tends to forget the past within a few hundred milliseconds.
Networks with a continuum of fixed points, known as continuous attractors \citep{khona2022}, have been proposed as models for representing continuous variables such as spatial locations \citep{samsonovich1997, stringer2002placecells, yang2022, wimmer2014}, head direction \citep{stringer2002headdirection, hulse2020, turner2017, turner2020neuroanatomical, vafidis2022, kim2019generation} or motor commands \citep{stringer2003}.

%Animals gather information about their surroundings through sensory modalities such as vision, audition, olfaction, and touch. Neuroscientists study how the brain processes these sensory inputs to build representations of the environment. For instance, during spatial navigation, the brain combines visual landmarks, sounds, and scents to construct a cognitive map of the environment. Efficient navigation involves decision-making, where animals assess different sensory cues, evaluate risks and rewards, and plan routes to enhance their survival chances.
%
%Dynamical systems approaches in the context of neural computation and information processing aim to understand the behavior of neural systems by modeling them as sets of differential equations. In this framework, the state of a neural system is described by a set of variables, typically representing the activity levels of individual neurons or neural populations. These variables evolve over time according to the dynamics specified by the differential equations. 

Working memory involves the temporary storage and manipulation of information over short time scales. The dynamics of an attractor network sustain persistent neural activity, maintaining the representation of the stored information in working memory, e.g., integrating angular velocity to update the head direction representation, which provides a framework for understanding memory \citep{barak2014, wolpert1995, goncalves2014, burak2009, goldman2007, aksay2007, noorman2022}. This persistent activity is robust to external distractions and noise, ensuring the stability of the working memory representation \citep{panichello2019, koulakov2002} in biological networks, yet this robustness is lacking in many theoretical models \citep{renart2003, seeholzer2019}.
The function of working memory has been modeled involving neural populations representing options in decision-making tasks, where the decision is reached when one population reaches a threshold level of activity or by comparing the dynamics of competing populations \citep{wong2007, wong2008}.

To understand how artificial neural networks compute and generate behaviors, accessing the underlying neural states and reverse engineering their temporal evolution is crucial. This approach can be applied to task-based modeling, where RNNs are trained to mimic cognitive functions observed in the brain \citep{darshan2022, barak2017recurrent}. This method can give insight into the possible computational principles underlying brain regions' operations. This analysis is challenging for large networks because of their black-box nature \citep{lipton2018, erasmus2021}.


One method for reverse engineering neural dynamics, fixed point analysis, simplifies complex global features of neural activity by examining stable fixed points \citep{sussillo2013blackbox, sussillo2014, beer2018, maheswaranathan2019universality, driscoll2022}. However, it is limited to systems with a finite set of stable fixed points. Recently, limit cycles have been explored, showing promise in understanding RNN dynamics \citep{pals2024}. Slow manifolds, capturing multi-scale dynamics, also hold potential. Integrating insights from limit cycles and slow manifolds into computational models could offer a more comprehensive framework for studying neural computation.



%Most, if not all, theories of recurrent neural computation are described using dynamical systems theory. Most theories were built on carefully designed systems to implement a computation, i.e., an input-output mapping. The most often used feature is the fixed point, i.e., a neural population state that remains constant over time. Networks with a continuum of fixed points, i.e., a continuous attractor, have been used to explain how the brain might represent continuous variables, such as the head direction and the location of the animal \citep{stringer2002headdirection, stringer2002placecells}.
%
%These models are remarkably delicate; even a minuscule change to the parameters (synaptic weights) can cause the continuum of fixed points to vanish (this property is called structural stability). This fragility underscores the challenge of understanding how biological neural networks, existing in a constantly changing and noisy biological substrate, perform under such conditions. Our current understanding of stability falls short in adequately capturing the intricacies of neural dynamics and their resilience to perturbations. 
%
%More generally, it is necessary to access the underlying neural states and reverse engineer their temporal evolution to understand how artificial neural networks or latent variable models compute and generate meaningful behaviors. Reverse engineering of dynamical systems descriptions of the brain has been applied to Recurrent neural networks (RNNs). Task-based modeling with RNNs has emerged as a popular way to infer the computational function of different brain regions to model large-scale neural recordings directly \citep{sussillo2014, barak2017recurrent}.
%
%Nevertheless, reverse engineering RNNs poses significant challenges \citep{marom2009}. RNNs often operate in high-dimensional spaces, which can complicate the analysis and interpretation of their internal representations and dynamics. Furthermore, RNNs often lack interpretability \citep{erasmus2021}, meaning that it can be hard to understand why they make particular predictions or produce certain outputs.
%
%One approach for this reverse engineering, fixed point analysis, assumes that the overall arrangement of fixed points of the dynamics can provide a simple and comprehensive explanation for the complex global features of neural activity observed in the system \citep{sussillo2013blackbox, maheswaranathan2019universality, beer2018}. We believe these issues have not been adequately addressed in models that describe neural computation. Fixed point analysis is only applicable to systems with a finite set of stable fixed points. Recently, limit cycles have been considered in the analysis. Limit cycles offer some promise in enhancing our understanding of the dynamics of RNNs, but further research is needed to fully explain their roles in neural computation. Furthermore, the concept of slow manifolds, which capture the dynamics of systems evolving on multiple time scales, holds promise in further enriching our understanding of RNNs and their computational properties. Integrating the insights gained from limit cycles and slow manifolds into computational models of neural networks could offer a more comprehensive framework for studying the complex dynamics of neural computation.
%
%The existing language used in theoretical neuroscience to describe neural computation is inadequate. We propose a new language specifically designed to articulate the complexities of working-memory type neural computation that can correctly describe the stability of the system yet provides an interpretable description of the computation. 



\section{Objectives}
The overarching objective of this project is to develop a more suitable mathematical language for understanding neural computation. In particular, we want a unifying framework to describe working memory type neural computation that encompasses the robustness properties of biological neural networks.

\subsection*{Aim 1: Re-representing neural dynamics in a new language for neural computation}
There exists no language that can describe neural computation for working memory and that  correctly captures the robustness of the brain for its implementation. With our proposed framework we attempt to answer the question what the underlying/fundamental dynamics/computations for working memory (specifically neural integration) are. For this, we create rigorous symbolic and visual languages to be able to describe the various ways the brain might implement working memory type computations. Our aim is to prove possible implementations of neural integration, along with other neural computations that relate to decision-making and navigation. This framework will enable us to gain a better understanding of the brain's remarkable information-processing ability necessary for the survival of an animal. 



\subsection*{Aim 2: Reverse engineer, write code}
The analysis proposed to describe the neural computation algorithm consists of three primary components. Firstly, identifying the recurrent sets of the system that represent the inputs. Secondly, describing how the input drives the network between these recurrent sets and implements the computation algorithm. Lastly, calculating the output mapping of the recurrent sets.
These fully capture the implementation of any working memory type neural computation and can be used to compare the found strategy to solve a task possible between two arbitrary networks.



\subsection*{Aim 3: }




\section{Detailed description}



\printbibliography

\end{document}
