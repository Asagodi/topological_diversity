\documentclass[12pt,letterpaper, onecolumn]{article}
%\documentclass{article}
%\documentclass{scrartcl}
\usepackage[left=1.2cm, right=1.2cm,top=1.5cm,bottom=1.5cm]{geometry}
\usepackage[utf8]{inputenc}
\usepackage{titling}\setlength{\droptitle}{-1em}   % This is your set screw
\usepackage{amssymb, amsmath, amsthm}
\usepackage{thmtools, mathtools, mathrsfs}
\usepackage{amsfonts}
\usepackage{xr-hyper}
\usepackage{hyperref}
%\usepackage[sort&compress,numbers]{natbib}
%\usepackage[round,sort&compress,numbers]{natbib}
\usepackage[%
    style=numeric,
    sorting=nyt,
  giveninits=true,
  backend=bibtex,
  doi=false,
  isbn=false,
  url=false,
  natbib,    
]{biblatex}
\AtEveryBibitem{%
  \clearfield{pages}%
}
\renewcommand{\bibfont}{\normalfont\footnotesize}
\usepackage{subcaption}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{float}
\usepackage{bm}
\usepackage{tikz}
\usetikzlibrary{positioning,matrix,arrows,decorations.pathmorphing}
\usepackage{tikz-cd} 
\usepackage{etoolbox}

\externaldocument{./additional_figures}

\definecolor{processblue}{cmyk}{0.8,0,0,0}
\definecolor{mpcolor}{rgb}{1, 0.1, 0.59}
\newcommand{\mpcomment}[1]{(\textbf{MP:\ }\textcolor{mpcolor}{#1})}

\newtheorem{theorem}{Theorem}
\newtheorem{prop}{Proposition}
\theoremstyle{definition}
\newtheorem{definition}{Definition}
\theoremstyle{remark}
\newtheorem{remark}{Remark}
 \usepackage{thmtools, thm-restate} \newtheorem{conjecture}[theorem]{Conjecture}

\newcommand{\reals}{\mathbb{R}}
\newcommand{\mb}[1]{\mathbb{#1}}
\newcommand{\mc}[1]{\mathcal{#1}}
\DeclareMathOperator{\Inv}{Inv}
\DeclareMathOperator{\innt}{int}
\newcommand{\probP}{\text{I\kern-0.15em P}}
 
 \addbibresource{ref.bib}
 \addbibresource{catniplab.bib}
\defbibenvironment{bibliography}
  {\noindent}
  {\unspace}
  {\printtext[labelnumberwidth]{%
    \printfield{labelprefix}%
    \printfield{labelnumber}}
    \addspace}
\renewbibmacro*{finentry}{\finentry\addspace}

%\title{A framework for Infinite Horizon Neural Computation} %on Compact Domains

\begin{document}
%\maketitle

\begin{center}
%\LARGE{\textbf{A for infinite horizon neural computation}}
%\LARGE{\bf An infinite-horizon language for neural computation}
%\LARGE{\bf   From Continuous Attractors to Multi-Scale Behavior}
\LARGE{\bf  Interpretable and robust neural computations for simple behaviors relying on working memory}
\end{center}
\begin{center}
{\textbf{\'Abel S\'agodi}}
\end{center}

\section*{Abstract}

The neural system, comprised of interconnected neurons with limited capacity, orchestrates essential cognitive processes such as perception, decision-making, and motor control by integrating sensory information with short-term memory.
Understanding these processes at an algorithmic level is pivotal for unraveling the fundamental principles governing neural function.
Dynamical systems theory, particularly the concept of stable fixed points, provides a formal framework for describing information processing in the brain.
Continuous attractors, networks with a continuum of fixed points, have emerged as models for representing continuous variables like spatial locations, head direction, and motor commands. 
Working memory, crucial for temporary storage and manipulation of information, relies on (continuous) attractor network dynamics to sustain persistent neural activity, ensuring stability against distractions and noise.
However, theoretical models often lack this robustness observed in biological networks.
In this project, we propose a novel framework aimed at describing neural computation while capturing the robustness properties observed in biological networks. By extending existing reverse engineering approaches for neural dynamics, we will characterize how artificial neural networks compute and generate behaviors and compare it to neural dynamics in animals. This endeavor holds promise for advancing our understanding of neural function and information processing, bridging the gap between theoretical models and biological reality.

\newpage
\section{State of the art}

The brain can process immediate sensory information and integrate it with short-term memory to produce essential survival behaviors such as decision-making.
The challenge of understanding these cognitive processes at an algorithmic or information-processing level is one of the primary goals in computational and theoretical neuroscience \citep{zoltowski2020general, pagan2022, whiteway2019, dyer2023simplest}.

The literature extensively employs concepts from dynamical systems theory to formally describe the algorithmic essence of information processing in the brain \citep{vyas2020computation}.
At the heart of current approaches lies the notions of ``stable fixed points'' \citep{sussillo2013blackbox, sussillo2014, beer2018, maheswaranathan2019universality, driscoll2022, mante2013context}, which represent the brain's internal states that remain consistent over time despite small perturbations.
The (stable) fixed points are extremely useful since they can maintain discrete states in neural systems for arbitrarily long times, where each neuron tends to forget the past within a few hundred milliseconds. % for timescales of seconds with neurons and synapse transmission operating mostly on time scales of tens of milliseconds and shorter
Networks with a continuum of fixed points, known as continuous attractors \citep{fung2010, khona2022, wu2008, wu2016}, have been proposed as models for representing continuous variables such as spatial locations \citep{samsonovich1997, stringer2002placecells, yang2022, wimmer2014, guanella2007model, gardner2022toroidal}, head direction \citep{stringer2002headdirection, hulse2020, turner2017, turner2020neuroanatomical, vafidis2022, kim2019generation}, motor commands \citep{stringer2003} and for the representation of other internal states \citep{nair2023, branco2016, seung2000stability}.

Working memory involves the temporary storage and manipulation of information over behaviorally relevant timescales. The dynamics of an attractor network sustain persistent neural activity, maintaining the representation of the stored information in working memory \citep{koulakov2002}, e.g., integrating angular velocity to update the head direction representation \citep{barak2013, barak2014, durstewitz2000, wolpert1995, goncalves2014, burak2009, goldman2007, aksay2007, noorman2022, cueva2021a, cueva2021b}.
%The function of working memory has been modeled via neural populations representing options in decision-making tasks \citep{gold2007neural}, where the decision is reached when one population reaches a threshold level of activity \citep{wong2007, wong2008, hocker2024, esnaola2022flexible}.

%noise and robustness
% Neural function is robust to noise \citep{faisal2008}, ensuring the stability of the working memory representation \citep{koulakov2002} in biological networks \citep{gallego2020}, yet this robustness is lacking in many theoretical models \citep{renart2003, seeholzer2019, machens2008}.
Neural function, such as the head direction representation, is very robust despite the constantly changing biological substrate, i.e., continually changing synaptic connections \citep{gallego2020, kim2019generation, flesch2023continual}.
On the other hand, for theoretical models such as continuous attractor networks noise in the synapses connections is problematic, as it destroys the continuum of fixed points even the smallest level of noise and is referred to as the ``fine-tuning problem'' (Figure 1) \citep{seung1996, renart2003}.
This discrepancy between biological neural networks and theoretical models poses a challenge for accurately capturing the dynamics of working memory and related cognitive processes via modeling \citep{calaim2022geometry, renart2003, seeholzer2019, machens2008}.
%GAP + proposal

Recurrent Neural Networks (RNNs) models of continuous attractors are inspired by neurobiological findings of continuous attractor networks in the brain, particularly in areas involved in spatial cognition, such as the hippocampus and the entorhinal cortex.
These models are increasingly popular in computational neuroscience for their ability to model neural dynamics, allowing researchers to explore hypotheses about neural function and behavior by training them on relevant tasks \citep{darshan2022, barak2017recurrent, durstewitz2023reconstructing, yang2019task, yang2019multiple, yang2020artificial, jarne2023b, song2016}. %task based
The vast array of possible solutions in RNNs for any desired task or behavior can be challenging to comprehend due to the high-dimensional dynamics \citep{lipton2018}.
Current reverse engineering methods cannot accurately reflect the multi-scale nature of RNNs because they capture only one time scale, focusing either on slow points \citep{sussillo2013blackbox}, limit cycles (non-constant, periodic behavior) \citep{pals2024, Zhao2016d} or slow manifolds \citep{ghazizadeh2021slow}.
%%
%
%GAP
Through an analysis of approximate solutions to working memory tasks, we intend to demonstrate how continuous attractors could be feasibly implemented in the noisy biological brain.
We propose a new language specifically designed to articulate the complexities of working-memory type neural computation that can correctly describe the stability of the system yet provides an interpretable description of the computation. 


%To understand how artificial neural networks compute and generate behaviors, accessing the underlying neural states and reverse engineering their temporal evolution is crucial. This approach can be applied to task-based modeling, where RNNs are trained to mimic cognitive functions observed in the brain \citep{darshan2022, barak2017recurrent, durstewitz2023reconstructing, yang2019task, yang2019multiple , yang2020artificial, jarne2023b, song2016}. This method can give insight into the possible computational principles underlying behavior. This analysis is challenging for large networks because of their black-box nature \citep{lipton2018, erasmus2021}.


%Most, if not all, theories of recurrent neural computation are described using dynamical systems theory. Most theories were built on carefully designed systems to implement a computation, i.e., an input-output mapping. The most often used feature is the fixed point, i.e., a neural population state that remains constant over time. Networks with a continuum of fixed points, i.e., a continuous attractor, have been used to explain how the brain might represent continuous variables, such as the head direction and the location of the animal \citep{stringer2002headdirection, stringer2002placecells}.
%
%These models are remarkably delicate; even a minuscule change to the parameters (synaptic weights) can cause the continuum of fixed points to vanish (this property is called structural stability). This fragility underscores the challenge of understanding how biological neural networks, existing in a constantly changing and noisy biological substrate, perform under such conditions. Our current understanding of stability falls short in adequately capturing the intricacies of neural dynamics and their resilience to perturbations. 
%
%More generally, it is necessary to access the underlying neural states and reverse engineer their temporal evolution to understand how artificial neural networks or latent variable models compute and generate meaningful behaviors. Reverse engineering of dynamical systems descriptions of the brain has been applied to Recurrent neural networks (RNNs). Task-based modeling with RNNs has emerged as a popular way to infer the computational function of different brain regions to model large-scale neural recordings directly \citep{sussillo2014, barak2017recurrent}.
%
%Nevertheless, reverse engineering RNNs poses significant challenges \citep{marom2009}. RNNs often operate in high-dimensional spaces, which can complicate the analysis and interpretation of their internal representations and dynamics. Furthermore, RNNs often lack interpretability \citep{erasmus2021}, meaning that it can be hard to understand why they make particular predictions or produce certain outputs.
%
%One approach for this reverse engineering, fixed point analysis, assumes that the overall arrangement of fixed points of the dynamics can provide a simple and comprehensive explanation for the complex global features of neural activity observed in the system \citep{sussillo2013blackbox, maheswaranathan2019universality, beer2018}. We believe these issues have not been adequately addressed in models that describe neural computation. Fixed point analysis is only applicable to systems with a finite set of stable fixed points. Recently, limit cycles have been considered in the analysis. Limit cycles offer some promise in enhancing our understanding of the dynamics of RNNs, but further research is needed to fully explain their roles in neural computation. Furthermore, the concept of slow manifolds, which capture the dynamics of systems evolving on multiple time scales, holds promise in further enriching our understanding of RNNs and their computational properties. Integrating the insights gained from limit cycles and slow manifolds into computational models of neural networks could offer a more comprehensive framework for studying the complex dynamics of neural computation.
%
%The existing language used in theoretical neuroscience to describe neural computation is inadequate. We propose a new language specifically designed to articulate the complexities of working-memory type neural computation that can correctly describe the stability of the system yet provides an interpretable description of the computation. 


\newpage
\section{Objectives}
%The overarching objective of this project is to develop a more suitable mathematical language for understanding neural computation.
%In particular, we want a unifying framework to describe working memory type neural computation that encompasses the robustness properties of biological neural networks.

The goal of this research is to enhance our analytical toolbox for understanding the dynamical systems that drive meaningful behavior in both biological and artificial neural networks.
We will focus on global descriptions of attractor dynamics, robustness, and fast-slow time scale decompositions involving working memory tasks.

\subsection*{Aim 1: Rescuing Continuous Attractors}
Do animals really employ continuous attractors for representing continuous variables, such as maintaining an internal representation of the head direction?
Our objective is to leverage the simplicity and intuitiveness of continuous attractors as an idealized abstraction of the slow manifolds.
By adjusting the speed or time constant of the neural dynamics, we will systematically uncover these approximate attractors.
Through the analysis of RNNs that provide approximate solutions to working memory tasks, we will demonstrate how continuous attractors could be feasibly implemented in the noisy biological brain.

\subsection*{Aim 2: An interpretable hierarchical ontology of multi-scale behavior}
Facing the vast array of possible solutions in RNNs for any desired task or behavior can seem overwhelming.
Our goal is to simplify this solution space through the use of fast-slow decomposition that coarse-grains attractors, and explicitly assign meaning to the attractors via their relation to the input and output spaces.
We will develop methods to categorize the potential mechanism, evaluate their robustness, and determine their effectiveness in simulation environments.
Moreover, through repeated coarse-graining, both temporally and spatially, we can build a hierarchy of descriptions with varying complexity that approximates the neural dynamics.

\subsection*{Aim 3: Deciphering working memory mechanisms from population activity in trained animals}
Building on the tools and methodologies developed in the previous aims, we will analyze neural recordings from animals performing tasks with a working memory component.
We will employ established machine learning techniques to infer a low-dimensional, nonlinear dynamical system from  neural data.
The inferred neural dynamics is not immediately interpretable due to spurious features that might be capturing irrelevant idiosynchracies of the noisy data and requires the analysis of introduced in Aim 2. %and what we have is suitable
We will compare theoretical models and trained RNNs with our multi-scale interpretation of the data-driven dynamical systems model.

%\newpage
%
%\subsection*{Aim 1: Developing a language for robust neural computation}
%Theoretical neuroscientists today face a challenge - the lack of a  framework that accurately reflects the robustness of biological neural networks while being easily interpretable \citep{lillicrap2019}.
%We propose a framework that relies on describing memory in terms of slow manifolds \citep{ghazizadeh2021slow} and robust asymptotic dynamics \citep{casey1996}.
%These structures provide a description of the memories and their decay at a range of timescales \citep{jaeger2023timescales} and allow for coarsening (via the nesting of attractors) \citep{braun2010}.
%We prove that these structures are robust to noise in the parameters \citep{Park2023a} and that they provide a general way for approximating continuous attractors \citep{inagaki2019}.
%This framework will allow us to describe the various ways the brain might implement working memory-type computation with a biological level of resilience.
%%Finally, we propose a coarsening of the description through an equivalence via the output mapping.
%
%\subsection*{Aim 2: Describing the implemented neural computation through recurrent sets}
%Designed models for neural computation are naturally easy to frame in the above language, but for trained RNNs or fitted models to neural data, the mechanism of the computation needs to be extracted. We will extract the implemented computation through three primary components of analysis. Firstly, we identify the recurrent sets and slow manifolds of the system that represent that correspond to meaningful input sequences or outputs, i.e., we implement a follow the attractor rule. Secondly, we describe how the input drives the network between these recurrent sets and implements the computation algorithm. Lastly, based on the output mapping of the recurrent sets, we extract the semantic meaning.
%This analysis is much more broadly applicable than existing approaches \citep{sussillo2013blackbox, sussillo2014, beer2018, maheswaranathan2019universality, driscoll2022, mante2013context, turner2021charting, turner2023, casey1996, valente2022extracting}.
%
%\subsection*{Aim 3: Comparison of trained RNNs and neural activity from trained animals}
%We employ the developed analysis technique across various tasks, examining both RNNs trained on the tasks and Neural ODEs (NODEs) fitted to neural activity recorded from animals trained on the same tasks \citep{Zhao2016d, pandarinath2018inferring, kim2021inferring}.
% Our analysis spans several tasks, including the Poisson clicks task \citep{brunton2013rats},
%  the delayed match-to-category task \citep{chaisangmongkon2017computing},
%  memory guided saccade task \citep{wimmer2014},
%  and context-dependent sensory integration task \citep{mante2013context}.
%   Through this comprehensive approach, we aim to gain insights into the neural dynamics underlying these diverse cognitive processes, shedding light on both the computational mechanisms employed by artificial neural networks and the neural substrates utilized by biological organisms during task performance.



\newpage
\section{Detailed description}
%TODO:  point out planned tasks and describe the respective timeline
\subsection*{Aim 1}
We propose a framework that relies on describing memory in terms of slow manifolds \citep{ghazizadeh2021slow}. % and robust asymptotic dynamics \citep{casey1996}.
%These structures provide a description of the memories and their decay at a range of timescales \citep{jaeger2023timescales} and allow for coarsening (via nesting attractors) \citep{braun2010}.
%We prove that these structures are robust to noise in the parameters \citep{Park2023a} and that they provide a general way for approximating continuous attractors.
This framework will allow us to describe the various ways the brain might implement working memory with a biological level of resilience.

\noindent
Deliverable: benchmark for robustness of models of neural integration

\subsubsection*{Aim 1.1: Unveiling the robustness of continuous attractors in recurrent neural networks}

%Do animals really employ continuous attractors for maintaining their head direction?

%The memory in biological networks is robust to minimal levels of both S- and D-type noise \citep{Park2023a}.


% Continuous attractors, despite their theoretical fragility in the face of D-type noise which should cause them to disappear instantly, demonstrate enduring practical behavior.
%   By adjusting the speed or time constant of the neural dynamics, we aim to uncover these approximate attractors.

We will address the ``fine-tuning problem'' describing the theoretical and practical brittleness of continuous attractors.
%Levels of abstraction
Our goal is to create a theoretical framework that takes advantage of the straightforward and intuitive nature of continuous attractors as an idealized abstraction of the slow manifolds locally.
%
%There have been efforts and remedies to lessen the degradation for particular implementations, often focusing on keeping the short-term behavior close to the continuous attractor case~\cite{Lim2012,Lim2013,Boerlin2013,Koulakov2002,Renart2003,gu2022}.
We show that not all continuous attractors are born equal, and there are gracefully degrading continuous attractors.
%In finite time, trajectories are well-behaved.
We will show that bounded continuous attractor always perturb into a slow manifold (very slow evolution compared to the evolution toward this manifold) with the same structure (a line attractor remains a line slow manifold, see Figure 2) and continue to be attractive.
%Animal behavior is finite time in nature and the longer the temporal distance the harder it is to learn in general.
The conditions for bounded continuous attractors are favorable in the recurrent neuronal networks: 
(1) mutual inhibition is widely present and evidence points to inhibition dominated dynamics,
(2) the neural state space is bounded due to physiological constraints, namely by a non-negative firing rate below and a maximum firing rate above.


%We identify memory components of the system as ``recurrent sets", which are composed of points where any two points can be connected by a trajectory that remains entirely within the set, irrespective of the presence of noise.
%Slow manifolds denote components where the system changes very slowly over time, which form the main backbone of the approximation.
%Lastly, we describe the asymptotic behavior, referring to the states and behaviors that the network ultimately converges to that gives insight into the very long-term behavior.
%All of these structures are inside an ``invariant set", regions within the neural space where the network consistently resides over time.
%Fast dynamics drive the system towards the invariant set, while in some cases an intermediate speed can be observed between two slow manifolds.
%We show that in this framework, a continuous attractor can be approximated by different compositions of a slow manifold and either a recurrent or an invariant set with different time scales.  


%Furthermore, we prove that all normally hyperbolic continuous attractors are surrounded by dynamical systems that have a slow invariant manifold that is diffeomorphic to the attractor (Figure 2). %Fig.~\ref{fig:bla_slowmanifolds}.
%This implies that for example normally hyperbolic ring attractors are surrounded in the space of dynamical systems by systems with an attractive slow invariant manifold that is composed of stable and saddle nodes and connecting orbits between them (Figure 3) and that such attractors have sufficient robustness to allow for homeostasis \citep{oleary2018homeostasis, niemeyer2021, kozachkov2022a, seeholzer2019}.
%There are various approximations that the brain might use to approximate such structural instability of theoretical models. For example, a line attractor can be approximated with fixed points  or a slow flow, between stable and unstable fixed point \citep{haviv2019, pollock2020}.


%    Through the analysis of artificial neural networks that provide approximate solutions to working memory tasks, we intend to demonstrate how continuous attractors could be feasibly implemented in the noisy biological brain.

%Robustness ananlysis
\subsubsection*{Aim 1.2: Assessing robustness of ring attractors}
Understanding how continuous attractors respond to these perturbations provides insight into their biological plausibility as models of neural dynamics in the brain.
Therefore, we analyze the following models of ring attractors: \citep{pollock2020, barak2021mapping, beiran2021, noorman2022}.
We assess their robustness numerically with the following robustness measures:
the shortest distance to a perturbation that destroys the attractive slow invariant manifold,
the probability of a fixed size perturbation that destroyes the continuous attractor,
the amount of maintained memories on the destroyed continuous attractor and
the average increase in speed as a function of the perturbation size.
This analysis relies on the identification of the possible perturbations of a ring attractor (an example is shown for \citep{noorman2022} in Figure 4).










\newpage

\subsection*{Aim 2}
By analyzing the dynamical behavior of a network, we gain a deeper understanding of how a network processes information and performs computations.
 We limit our analysis to working memory type computation with a long-term component. Examples include  neural integration, evidence accumulation, and decision-making.
%Previously, an in-depth analysis of the behavior of small systems has been performed \citep{beer1995ctrnn, beer1995interaction, beer1995computational, beer2006, beer2023}. % and Jaeger \citep{jaeger2021, jaeger2023theory} have been explored thus far.


\noindent
Deliverable: Open-source analysis tools for automated model identification and simplification

\subsubsection*{Aim 2.1: Reverse engineering and coarse-graining neural computation on different timescales}
We will extract the algorithm, defined as an input-output mapping, through three primary analysis components.
%Encoding, past
Firstly, we identify the system's recurrent sets and slow manifolds that correspond to meaningful input sequences or outputs \citep{goudar2018}. 
We achieve this by computing the Morse decomposition from the numerically integrated trajectories relevant to the task \citep{mischaikow1999, arai2009database}.
%Decoding, future
Secondly, we describe how the input drives the network between attractors by estimating the basins of attraction and which areas are reached after a sequence of inputs with the network initialized at an attractor. 
This approach is a generalization of the ``follow the fixed point rule'' \citep{sussillo2013blackbox} and we call it the ``follow the attractor rule''.
%We do this at different timescales by separating the system into slow and fast components, which allows us to construct slow manifolds as well \citep{jones1995, kuehn2015, casey1996}.
%Timescales
%We determine how constraints on the time window or time scale used to assess the correspondence in the implemented computation in terms of the input-output relationship contribute to these different kinds of approximation.


Lastly, based on the output mapping of the recurrent sets, we extract the behavioral-semantic meaning by identifying the output mapping of all the recurrent sets and slow manifolds. Furthermore, the same output can elicited by different activity patterns in different behaviors or contexts, and we, therefore, group recurrent sets according to a metric in the output space \citep{athalye2023, myers2022}.
Timescale and grouping through the output mapping allow for the coarsening of the representation of the algorithm via the merging of attractors \citep{braun2010}.
The coarsening provides interpretability, as we can flexibly coarsen the memory states to a suitable simplicity for human understanding.

%
\subsubsection*{Aim 2.2: Analysisng trained RNNs on working memory tasks}

We test our analysis method on hand-desinged attractor networks, such as different approximations of ring attractors.
The analysis of hand-designed attractor networks should accurately identify key dynamical features such as stable fixed points and slow manifolds.
%
Furthermore, we analyze RNNs trained with backpropagation through time on the Poisson clicks (Figure 5), context-dependent decision-making, angular velocity integration task (Figure 6), memory-guided saccades  and delayed match-to-category tasks \citep{farrell2022, schuessler2020}.
We use mean-squared error loss for the matching tasks and cross-entropy for the decision-making tasks to train the networks.
We enforce long-term  memory maintenance through gradient flossing \citep{engelken2023b} and equilibrium propagation \citep{laborieux2023}.
The analysis should enhance the interpretability of the network's functionality by coarsening and should allow us to group RNNs together in a manageable number of groups that solve the task in the same way.

%angular velocity integration task? (Figure 6)




%
%Fig.~\ref{fig:angular_task}
%
%Fig.~\ref{fig:slowmanifolds}


%Universality of Linear Recurrences Followed by Nonlinear Projection \cite{orvieto2023a}
%CTRNNs \citep{funahashi1993approximation}




\newpage

\subsection*{Aim 3}

By comparing trained RNNs on various tasks and the biological neural dynamics, we gain insight into the neural implementations of integration and decision making.


\noindent
Deliverable:  Comprehensive insights into the neural implementations of integration and decision-making, derived from the analysis of trained RNNs on analogous tasks and fitting dynamical systems to neural recordings.

\subsubsection*{Aim 3.1: Fitting dynamical systems to neural recordings.}

%Datasets.
For this aim, we will utilize various datasets of animals performing simple tasks that could potentially have interpretable neural explanations and which have pairwise overlapping components so that we can uncover common computational principles.
We will use recordings from the rat motor cortex for the Poisson clicks and context-dependent decision-making tasks and data from macaques for the memory-guided saccades and delayed match-to-category tasks.
%
%Methods
We fit dynamical systems to neural data \citep{Zhao2016d} with two different methods:
 Neural ODEs \citep{kim2021inferring} and 
 seq-VAEs \citep{pandarinath2018inferring}, as they have both proven to be successfull at capturing neural dynamics.
%dynamical systems reconstruction \citep{schmidt2019}. % through the Neural Latents Benchmark \citep{pei2021neural}.
By fitting dynamical systems to neural recordings, we aim to elucidate how neurons integrate sensory information and make decisions, providing valuable insights into the neural basis of cognitive functions.
We will then decipher how the neural dynamics might produce the behavior in the task by extracting meaningful information about how these networks process information and perform computations related to working memory tasks with the analysis developed in Aim 2. 
In particular, we hope to identify different timescales relevant for the tasks under consideration.

%Comparisons
\subsubsection*{Aim 3.2: Identifying mechanisms of neural computation}
We will compare the different neural dynamics with our method to establish underlying or shared principles of working memory mechanisms in different tasks.
Moreover, comparing the dynamics of trained RNNs from Aim 2 with those observed in biological neural recordings allows us to validate the effectiveness of our computational models in capturing essential aspects of neural computation.
%We aim to identify the underlying mechanisms of neural computation by comparing trained RNNs from Aim 2 with fitted models of neural dynamics.
 The comparison we will develop will be based on the Morse decomposition that identifies correspondece of the topological structure of recurrent sets and connecting orbits \citep{arai2009database, kaczynski2004computational}.
We identify the best corresponding RNN for each task and dataset as an explanation of how the brain implements working memory mechanisms \citep{levenstein2023}.
 
%less prone to misinterpretation?



\newpage
\printbibliography

\end{document}
