{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4a526c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "from scripts.avi_rnn import *\n",
    "from scripts.utils import set_seed\n",
    "from scripts.ds_class import *\n",
    "from scripts.homeos import *\n",
    "from scripts.plotting import *\n",
    "from scripts.fit_motif import *\n",
    "from scripts.time_series import *\n",
    "from scripts.ra import *\n",
    "from scripts.exp_tools import *\n",
    "exp_folder = \"experiments/avi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81668b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "np.random.seed(random_seed)\n",
    "T=25.6/2\n",
    "dt=.1 \n",
    "batch_size=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d9263c",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = angularintegration_task_constant(T=T, dt=dt, speed_range=[0.,0.], sparsity=1, random_angle_init='equally_spaced');\n",
    "for N in [64]:\n",
    "    sub_exp = f\"N{N}_T128_noisy\"\n",
    "    for activation in [\"recttanh\", \"relu\", \"tanh\"]:\n",
    "        folder = os.path.join(exp_folder, sub_exp, activation)\n",
    "        exp_list = glob.glob(os.path.join(folder, \"res*\"))\n",
    "        nact_exp = exp_folder +  \"/all_trajs\" + f\"/N{N}_{activation}\"\n",
    "        print(f\"Processing {nact_exp}\")\n",
    "        for exp_i in range(len(exp_list)):\n",
    "            path = exp_list[exp_i]\n",
    "            try:\n",
    "                net, result = load_net_path(path)\n",
    "            except:\n",
    "                print(f\"Error loading {path}\")\n",
    "                continue\n",
    "            net.eval()    \n",
    "            input, target, mask, output, trajectories = simulate_rnn_with_task(net, task, T, '', batch_size=batch_size)\n",
    "            net_id = os.path.basename(path).split(\"_\")[-1].split(\".\")[0]\n",
    "            print(net_id, trajectories.shape)\n",
    "            os.makedirs(nact_exp, exist_ok=True)\n",
    "            np.save(f'{nact_exp}/trajectories_{net_id}.npy', trajectories.copy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835deb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "archetypes_2d = ['lds', 'lc', 'ring', 'bla', 'bistable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b352c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 64\n",
    "activation = \"recttanh\"\n",
    "exp_dir = Path('experiments')\n",
    "data_dir = exp_dir  / 'avi' / \"all_trajs\" / f\"N{N}_{activation}\"\n",
    "\n",
    "npy_files = list(data_dir.glob('*.npy'))\n",
    "print(npy_files)\n",
    "for file in npy_files:\n",
    "    target_name = file.name.removesuffix('.npy')\n",
    "    save_dir = exp_dir / 'avi' / \"fit_motifs\" / f\"N{N}_{activation}\"\n",
    "    print(target_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63118ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run on last RNN only\n",
    "for archetype in archetypes_2d:\n",
    "    run_on_target(target_name, save_dir=save_dir, data_dir=data_dir, ds_motif=archetype, analytic=True, canonical=True, jac_lambda_reg=.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f46df13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CIT_",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
