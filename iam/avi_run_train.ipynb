{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4a526c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "from scripts.avi_rnn import *\n",
    "from scripts.utils import set_seed\n",
    "from scripts.ds_class import *\n",
    "from scripts.homeos import *\n",
    "from scripts.plotting import *\n",
    "from scripts.fit_motif import *\n",
    "from scripts.time_series import *\n",
    "from scripts.ra import *\n",
    "exp_folder = \"experiments\\\\avi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81668b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "np.random.seed(random_seed)\n",
    "T=25.6/2\n",
    "dt=.1 \n",
    "batch_size=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d9263c",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = angularintegration_task_constant(T=T, dt=dt, speed_range=[0.,0.], sparsity=1, random_angle_init='equally_spaced');\n",
    "for N in [64]:\n",
    "    sub_exp = f\"N{N}_T128_noisy\"\n",
    "    for activation in [\"recttanh\", \"relu\", \"tanh\"]:\n",
    "        folder = os.path.join(exp_folder, sub_exp, activation)\n",
    "        exp_list = glob.glob(os.path.join(folder, \"res*\"))\n",
    "        nact_exp = exp_folder +  \"/all_trajs\" + f\"/N{N}_{activation}\"\n",
    "        print(f\"Processing {nact_exp}\")\n",
    "        for exp_i in range(len(exp_list)):\n",
    "            path = exp_list[exp_i]\n",
    "            try:\n",
    "                net, result = load_net_path(path)\n",
    "            except:\n",
    "                print(f\"Error loading {path}\")\n",
    "                continue\n",
    "            net.eval()    \n",
    "            input, target, mask, output, trajectories = simulate_rnn_with_task(net, task, T, '', batch_size=batch_size)\n",
    "            net_id = os.path.basename(path).split(\"_\")[-1].split(\".\")[0]\n",
    "            print(net_id, trajectories.shape)\n",
    "            os.makedirs(nact_exp, exist_ok=True)\n",
    "            np.save(f'{nact_exp}/trajectories_{net_id}.npy', trajectories.copy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faf4d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_on_target(target_name, save_dir, data_dir, ds_motif = 'ring', analytic = True,\n",
    "                    alpha_init = None, velocity_init = None, vf_on_ring_enabled = False, #if analytic then not used\n",
    "                    homeo_type = 'node', layer_sizes = 1*[64], batch_size = 32,\n",
    "                    train_ratio = 0.8, training_pairs = False, \n",
    "                    lr = 0.01, num_epochs = 1000, \n",
    "                    random_seed = 313):\n",
    "    save_dir = os.path.join(save_dir, ds_motif)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    set_seed(random_seed)\n",
    "     \n",
    "    trajectories_target = np.load(data_dir / f'{target_name}.npy')\n",
    "    dim = trajectories_target.shape[2]\n",
    "    tsteps = trajectories_target.shape[1]\n",
    "    B = trajectories_target.shape[0]\n",
    "    \n",
    "    homeo_type = 'node'\n",
    "    dt = .1\n",
    "    time_span = torch.tensor([0.0, T-dt/2.])\n",
    "    if training_pairs:\n",
    "        time_span = torch.tensor([0.0, dt])\n",
    "    ds_motif = 'ring'\n",
    "    ds_params = {\n",
    "        'ds_motif': ds_motif, 'dim': dim, 'dt': dt, 'time_span': time_span,\n",
    "        'analytic': analytic, 'vf_on_ring_enabled': vf_on_ring_enabled,\n",
    "        'alpha_init': alpha_init, 'velocity_init': velocity_init\n",
    "    }\n",
    "    homeo_params = {'homeo_type': homeo_type, 'dim': dim, 'layer_sizes': layer_sizes, 'activation': nn.ReLU, 'init_type': None}\n",
    "    training_params = {'lr': lr,'num_epochs': num_epochs,'annealing_params': {'dynamic': False, 'initial_std': 0.0, 'final_std': 0.0},'early_stopping_patience': 1000,'batch_size': batch_size,'use_inverse_formulation': True}\n",
    "    trajectories_target_full, trajectories_target, mean, std = normalize_scale_pair(torch.tensor(trajectories), training_pairs=training_pairs)\n",
    "\n",
    "    train_ratio = 0.8\n",
    "    n_train = int(train_ratio * B)\n",
    "    n_test = B - n_train\n",
    "    train_set, test_set = random_split(trajectories_target_full, [n_train, n_test])\n",
    "    trajectories_target_train = trajectories_target[train_set.indices]\n",
    "    trajectories_target_test = trajectories_target[test_set.indices]\n",
    "\n",
    "    # target_ra_points = get_homeo_invman(interpolated_homeo)\n",
    "    target_ra_points = trajectories_target[:, -1, :].reshape(-1, dim)\n",
    "    #target_ra_points = (target_ra_points - mean.detach().numpy()) / std.detach().numpy()\n",
    "\n",
    "    homeo = build_homeomorphism(homeo_params)\n",
    "    source_system_ra = build_ds_motif(**ds_params)\n",
    "    homeo_ds_net = Homeo_DS_Net(homeo, source_system_ra)\n",
    "    homeo_ds_net, losses, grad_norms = train_homeo_ds_net_batched(\n",
    "        homeo_ds_net=homeo_ds_net,\n",
    "        trajectories_target=trajectories_target_train,\n",
    "        **training_params\n",
    "    )\n",
    "    homeo_ds_net.eval()\n",
    "\n",
    "    #test\n",
    "    _, _, training_loss = test_single_homeo_ds_net(homeo_ds_net=homeo_ds_net, trajectories_target=trajectories_target_train)\n",
    "    _, _, test_loss = test_single_homeo_ds_net(homeo_ds_net=homeo_ds_net, trajectories_target=trajectories_target_test)\n",
    "    traj_src_np, traj_trans_np, _ = test_single_homeo_ds_net(homeo_ds_net=homeo_ds_net, trajectories_target=trajectories_target)\n",
    "    inv_man = homeo_ds_net.invariant_manifold(100).detach().numpy()\n",
    "    jac_norm_frobenius = jacobian_norm_over_batch(homeo_ds_net.homeo_network, trajectories_target.reshape(-1,dim), norm_type='fro').detach().numpy()\n",
    "    jac_norm_spectral = jacobian_norm_over_batch(homeo_ds_net.homeo_network, trajectories_target.reshape(-1,dim), norm_type='spectral').detach().numpy()\n",
    "\n",
    "    np.savez(\n",
    "    f\"{save_dir}/results_{target_name}.npz\",\n",
    "    jac_fro=jac_norm_frobenius,\n",
    "    jac_spec=jac_norm_spectral,\n",
    "    training_loss=training_loss,\n",
    "    test_loss=test_loss,\n",
    "    losses=np.array(losses),  \n",
    "    grad_norms=np.array(grad_norms),\n",
    "    inv_man=inv_man,\n",
    "    target_ra_points=target_ra_points,\n",
    ")\n",
    "\n",
    "    save_homeo_ds_net(homeo_ds_net, f\"{save_dir}/homeo_{target_name}.pth\")\n",
    "    np.save(f\"{save_dir}/traj_motif_transformed_{target_name}.npy\", traj_trans_np) \n",
    "    np.save(f\"{save_dir}/traj_motif_source_{target_name}.npy\", traj_src_np) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b352c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 64\n",
    "activation = \"recttanh\"\n",
    "exp_dir = Path('experiments')\n",
    "data_dir = exp_dir  / 'avi' / \"all_trajs\" / f\"N{N}_{activation}\"\n",
    "\n",
    "npy_files = list(data_dir.glob('*.npy'))\n",
    "print(npy_files)\n",
    "for file in npy_files:\n",
    "    target_name = file.name.removesuffix('.npy')\n",
    "    save_dir = exp_dir / 'avi' / \"fit_motifs\" / f\"N{N}_{activation}\"\n",
    "    print(target_name)\n",
    "    run_on_target(target_name, save_dir, data_dir, ds_motif = 'ring')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CIT_",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
